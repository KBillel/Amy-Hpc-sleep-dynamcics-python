{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import neuroseries as nts\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns \n",
    "import bk.load\n",
    "import bk.signal\n",
    "import bk.plot\n",
    "import importlib; \n",
    "importlib.reload(bk.signal)\n",
    "importlib.reload(bk.plot)\n",
    "%matplotlib qt\n",
    "import basefunction.anass_load as at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already saved in Numpy format, loading them from here:\n",
      "LoadingRat08-20130713-neurons.npy\n",
      "LoadingRat08-20130713-NeuronsShanks.npy\n"
     ]
    }
   ],
   "source": [
    "bk.load.path = '/media/billel/GGLab-01-BK/DATA/Rat08-20130713/'\n",
    "bk.load.session = 'Rat08-20130713'\n",
    "\n",
    "session = 'Rat08-20130713' \n",
    "neurons,shanks = loadSpikeData(bk.load.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time (s)\n",
       "24.42490      NaN\n",
       "82.58885      NaN\n",
       "101.86240     NaN\n",
       "138.35750     NaN\n",
       "138.65065     NaN\n",
       "               ..\n",
       "22663.57715   NaN\n",
       "22672.92575   NaN\n",
       "22675.11920   NaN\n",
       "22675.61620   NaN\n",
       "22676.91705   NaN\n",
       "Length: 15784, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons[0].as_units('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSpikeData(path, index=None, fs = 20000):  \n",
    "    ### Adapted from Viejo github https://github.com/PeyracheLab/StarterPack/blob/master/python/wrappers.py\n",
    "    ### Modified by BK 06/08/20\n",
    "    ### Modification are explicit with comment\n",
    "    \"\"\"\n",
    "    if the path contains a folder named /Analysis, \n",
    "    the script will look into it to load either\n",
    "        - SpikeData.mat saved from matlab\n",
    "        - SpikeData.h5 saved from this same script\n",
    "    if not, the res and clu file will be loaded \n",
    "    and an /Analysis folder will be created to save the data\n",
    "    Thus, the next loading of spike times will be faster\n",
    "    Notes :\n",
    "        If the frequency is not givne, it's assumed 20kH\n",
    "    Args:\n",
    "        path : string\n",
    "\n",
    "    Returns:\n",
    "        dict, array    \n",
    "    \"\"\"\n",
    "    \n",
    "#     try session:\n",
    "#     except: print('Did you load a session first?')\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(\"The path \"+path+\" doesn't exist; Exiting ...\")\n",
    "        sys.exit()\n",
    "    if os.path.exists(path + '//' + session +'-neurons.npy'):\n",
    "        print('Data already saved in Numpy format, loading them from here:')\n",
    "        print(session +'-neurons.npy')\n",
    "        neurons = np.load(path+'//' + session +'-neurons.npy',allow_pickle=True)\n",
    "        print(session +'-NeuronsShanks.npy')\n",
    "        shanks = np.load(path+'//' + session +'-neuronsShanks.npy',allow_pickle=True)\n",
    "        \n",
    "        return neurons,shanks\n",
    "                      \n",
    "    files = os.listdir(path)\n",
    "    # Changed 'clu' to '.clu.' same for res as in our dataset we have file containing the word clu that are not clu files\n",
    "    clu_files     = np.sort([f for f in files if '.clu.' in f and f[0] != '.'])\n",
    "    res_files     = np.sort([f for f in files if '.res.' in f and f[0] != '.'])\n",
    "    \n",
    "    # Changed because some files have weird names in GG dataset because of some backup on clu/res files\n",
    "    # Rat10-20140627.clu.10.07.07.2014.15.41 for instance\n",
    "    \n",
    "    clu_files = clu_files[[len(i) < 22 for i in clu_files]]\n",
    "    res_files = res_files[[len(i) < 22 for i in res_files]]\n",
    "    \n",
    "\n",
    "    clu1         = np.sort([int(f.split(\".\")[-1]) for f in clu_files])\n",
    "    clu2         = np.sort([int(f.split(\".\")[-1]) for f in res_files])\n",
    "    \n",
    "#     if len(clu_files) != len(res_files) or not (clu1 == clu2).any():\n",
    "#         print(\"Not the same number of clu and res files in \"+path+\"; Exiting ...\")\n",
    "#         sys.exit()\n",
    "#   Commented this because in GG dataset their .clu.12.54.21.63 files that mess up everything ...\n",
    "    \n",
    "    count = 0\n",
    "    spikes = []\n",
    "    basename = clu_files[0].split(\".\")[0]\n",
    "    idx_clu_returned = []\n",
    "    for i, s in zip(range(len(clu_files)),clu1):\n",
    "        clu = np.genfromtxt(os.path.join(path,basename+'.clu.'+str(s)),dtype=np.int32)[1:]\n",
    "        print('Loading '+basename + '.clu.' + str(s))\n",
    "        if np.max(clu)>1:\n",
    "            res = np.genfromtxt(os.path.join(path,basename+'.res.'+str(s)))\n",
    "            tmp = np.unique(clu).astype(int)\n",
    "            idx_clu = tmp[tmp>1]\n",
    "            idx_clu_returned.extend(idx_clu) # Allow to return the idx of each neurons on it's shank. Very important for traceability\n",
    "            idx_col = np.arange(count, count+len(idx_clu))       \n",
    "            tmp = pd.DataFrame(index = np.unique(res)/fs,\n",
    "                                columns = pd.MultiIndex.from_product([[s],idx_col]),\n",
    "                                data = 0, \n",
    "                                dtype = np.uint16)\n",
    "            \n",
    "            for j, k in zip(idx_clu, idx_col):\n",
    "                tmp.loc[res[clu==j]/fs,(s,k)] = np.uint16(k+1)\n",
    "            spikes.append(tmp)\n",
    "            count+=len(idx_clu)\n",
    "\n",
    "    #Returning a list instead of dict in order to use list of bolean.\n",
    "    toreturn =  []\n",
    "    shank = []\n",
    "    for s in spikes:\n",
    "        shank.append(s.columns.get_level_values(0).values)\n",
    "        sh = np.unique(shank[-1])[0]\n",
    "        for i,j in s:\n",
    "            toreturn.append(nts.Tsd(t=s[(i,j)].replace(0,np.nan).dropna().index.values, time_units = 's'))\n",
    "            #To return was change to nts.Tsd instead of nts.Ts as it has bug for priting (don't know where it is coming from)\n",
    "\n",
    "    del spikes\n",
    "    shank = np.hstack(shank)\n",
    "    \n",
    "    neurons = np.array(toreturn,dtype = 'object')\n",
    "    shanks = np.array([shank, idx_clu_returned]).T\n",
    "    \n",
    "    print()\n",
    "    print('Saving data in Numpy format :')\n",
    "    \n",
    "    print('Saving ' + session +'-neurons.npy')\n",
    "    np.save(path + '//' + session + '-neurons',neurons)\n",
    "    \n",
    "    print('Saving ' + session +'-neuronsShanks.npy')\n",
    "    np.save(path + '//' + session + '-neuronsShanks',shanks)\n",
    "                      \n",
    "    return neurons,shanks  #idx_clu is returned in order to keep indexing consistent with Matlab code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
