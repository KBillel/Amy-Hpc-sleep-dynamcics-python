{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib qt\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global x,y,pause\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.imshow(frame)\n",
    "    try:\n",
    "        x\n",
    "    except:\n",
    "        x = [0,0]\n",
    "    try:\n",
    "        y\n",
    "    except:\n",
    "        y = [0,0]\n",
    "    \n",
    "    if str(event.button) == \"MouseButton.LEFT\":\n",
    "        x[0], y[0] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.RIGHT\":\n",
    "        x[1], y[1] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.MIDDLE\":\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "        pause = False\n",
    "        \n",
    "    for i,j in zip(x,y):\n",
    "        plt.axvline(i)\n",
    "        plt.axhline(j)\n",
    "        plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Y:/elevated_plus_maze/'\n",
    "videos = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4') and not file.endswith('labeled.mp4'): videos.append(os.path.join(subdirs,file))\n",
    "\n",
    "            \n",
    "config_path = 'E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y:/elevated_plus_maze/Rat06-20201123\\\\Rat06_201123_152703\\\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat07-20201123\\\\Rat07_201123_154150\\\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat08-20201123\\\\Rat08_201123_155820\\\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat09-20201130\\\\Rat09_201130_145247\\\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat10-20201130\\\\Rat10_201130_150837\\\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat11-20201130\\\\Rat11_201130_152319\\\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat12-20201130\\\\Rat12_201130_153751\\\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = []\n",
    "\n",
    "for v in videos:\n",
    "    try:\n",
    "        del x,y\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cap = cv2.VideoCapture(v)\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    pause = True\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.imshow(frame)\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    \n",
    "    while pause:\n",
    "        plt.pause(0.1)\n",
    "        \n",
    "    plt.close('all')\n",
    "    crop.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([276.55627705627705, 1224.088744588745],\n",
       "  [14.461038961038867, 654.4610389610389]),\n",
       " ([290.4090909090909, 1221.3181818181822],\n",
       "  [20.002164502164305, 637.8376623376622]),\n",
       " ([265.47402597402595, 1210.235930735931],\n",
       "  [22.772727272727025, 640.6082251082249]),\n",
       " ([282.0974025974026, 1254.5649350649355],\n",
       "  [42.166666666666515, 712.642857142857]),\n",
       " ([254.39177489177484, 1235.170995670996],\n",
       "  [39.396103896103796, 668.3138528138527]),\n",
       " ([254.39177489177484, 1201.9242424242427],\n",
       "  [14.461038961038867, 635.0670995670995]),\n",
       " ([251.62121212121212, 1254.5649350649355],\n",
       "  [17.231601731601586, 676.6255411255411])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [276, 1224, 14, 654]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/17534 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat06-20201123\\Rat06_201123_152703\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4\n",
      "Y:\\elevated_plus_maze\\Rat06-20201123\\Rat06_201123_152703  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat06-20201123\\Rat06_201123_152703\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4\n",
      "Duration of video [s]:  584.47 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17534  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 276 x2 = 1224 y1 = 14 y2 = 654. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17675it [10:58, 26.84it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat06-20201123\\Rat06_201123_152703...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat06-20201123\\Rat06_201123_152703\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:963: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:975: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [290, 1221, 20, 637]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/17662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat07-20201123\\Rat07_201123_154150\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4\n",
      "Y:\\elevated_plus_maze\\Rat07-20201123\\Rat07_201123_154150  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat07-20201123\\Rat07_201123_154150\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4\n",
      "Duration of video [s]:  588.73 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17662  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 290 x2 = 1221 y1 = 20 y2 = 637. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17776it [11:00, 26.68it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17776it [11:03, 26.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat07-20201123\\Rat07_201123_154150...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat07-20201123\\Rat07_201123_154150\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [265, 1210, 22, 640]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/17839 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat08-20201123\\Rat08_201123_155820\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4\n",
      "Y:\\elevated_plus_maze\\Rat08-20201123\\Rat08_201123_155820  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat08-20201123\\Rat08_201123_155820\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4\n",
      "Duration of video [s]:  594.63 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17839  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 265 x2 = 1210 y1 = 22 y2 = 640. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17978it [11:14, 26.34it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17978it [11:16, 26.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat08-20201123\\Rat08_201123_155820...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat08-20201123\\Rat08_201123_155820\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [282, 1254, 42, 712]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/17539 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat09-20201130\\Rat09_201130_145247\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4\n",
      "Y:\\elevated_plus_maze\\Rat09-20201130\\Rat09_201130_145247  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat09-20201130\\Rat09_201130_145247\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4\n",
      "Duration of video [s]:  584.63 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17539  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 282 x2 = 1254 y1 = 42 y2 = 712. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17675it [11:42, 24.99it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17675it [11:44, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat09-20201130\\Rat09_201130_145247...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat09-20201130\\Rat09_201130_145247\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [254, 1235, 39, 668]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/17755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat10-20201130\\Rat10_201130_150837\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4\n",
      "Y:\\elevated_plus_maze\\Rat10-20201130\\Rat10_201130_150837  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat10-20201130\\Rat10_201130_150837\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4\n",
      "Duration of video [s]:  591.83 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17755  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 254 x2 = 1235 y1 = 39 y2 = 668. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17877it [11:31, 25.71it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17877it [11:33, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat10-20201130\\Rat10_201130_150837...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat10-20201130\\Rat10_201130_150837\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [254, 1201, 14, 635]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/17943 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat11-20201130\\Rat11_201130_152319\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4\n",
      "Y:\\elevated_plus_maze\\Rat11-20201130\\Rat11_201130_152319  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat11-20201130\\Rat11_201130_152319\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4\n",
      "Duration of video [s]:  598.1 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17943  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 254 x2 = 1201 y1 = 14 y2 = 635. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18079it [11:26, 26.06it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18079it [11:27, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat11-20201130\\Rat11_201130_152319...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat11-20201130\\Rat11_201130_152319\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [251, 1254, 17, 676]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:/classical_fear_conditionning/classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/17936 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat12-20201130\\Rat12_201130_153751\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4\n",
      "Y:\\elevated_plus_maze\\Rat12-20201130\\Rat12_201130_153751  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat12-20201130\\Rat12_201130_153751\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4\n",
      "Duration of video [s]:  597.87 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17936  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 251 x2 = 1254 y1 = 17 y2 = 676. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18079it [12:21, 24.38it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17936\n",
      "Saving results in Y:\\elevated_plus_maze\\Rat12-20201130\\Rat12_201130_153751...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat12-20201130\\Rat12_201130_153751\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\Billel.Khouader\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.analyze_videos(config_path,v,cropping=c,save_as_csv=True)\n",
    "    dlc.filterpredictions(config_path,v,save_as_csv = True,filtertype='arima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pickle'): metadata.append(os.path.join(subdirs,file))\n",
    "\n",
    "del metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in videos:\n",
    "    dlc.create_labeled_video(config_path,v,filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = videos[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\classical_fear_conditionning\\\\Rat12-20201117\\\\Rat12_201117_181452\\\\Basler_acA1300-200uc__23039139__20201117_181456585.mp4'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_labeled_video(config_path,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    \n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    \n",
    "    dlc.extract_outlier_frames(config_path,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.launch_dlc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
