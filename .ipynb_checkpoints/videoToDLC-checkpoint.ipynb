{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib qt\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global x,y,pause\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.imshow(frame)\n",
    "    try:\n",
    "        x\n",
    "    except:\n",
    "        x = [0,0]\n",
    "    try:\n",
    "        y\n",
    "    except:\n",
    "        y = [0,0]\n",
    "    \n",
    "    if str(event.button) == \"MouseButton.LEFT\":\n",
    "        x[0], y[0] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.RIGHT\":\n",
    "        x[1], y[1] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.MIDDLE\":\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "        pause = False\n",
    "        \n",
    "    for i,j in zip(x,y):\n",
    "        plt.axvline(i)\n",
    "        plt.axhline(j)\n",
    "        plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Y://fear_conditionning_ptsd/'\n",
    "videos = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4') and not file.endswith('labeled.mp4'): videos.append(os.path.join(subdirs,file))\n",
    "\n",
    "            \n",
    "config_path = 'E:\\classical_fear_conditionning\\classical_fear_conditionning-BM-2020-11-20\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y://fear_conditionning_ptsd/Rat07\\\\Rat07-20201109\\\\Basler_acA1300-200uc__23039139__20201109_170654127.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat07\\\\Rat07-20201109\\\\Rat07_201109_121627\\\\Basler_acA1300-200uc__23039139__20201109_121631619.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat07\\\\Rat07-20201109\\\\Rat07_201109_161952\\\\Basler_acA1300-200uc__23039139__20201109_161956558.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat08\\\\Rat08-20201109\\\\Basler_acA1300-200uc__23039139__20201109_171631263.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat08\\\\Rat08-20201110\\\\Rat08-20201110_201110_113809\\\\Basler_acA1300-200uc__23039139__20201110_113811828.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat08\\\\Rat08-20201110\\\\Rat08-20201110_201110_153156\\\\Basler_acA1300-200uc__23039139__20201110_153159547.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat08\\\\Rat08-20201110\\\\Rat08-20201110_201110_161904\\\\Basler_acA1300-200uc__23039139__20201110_161906309.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat13\\\\Rat13-20201202\\\\Rat13_201202_183404\\\\Basler_acA1300-200uc__23039139__20201202_183406294.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat13\\\\Rat13-20201203\\\\Rat13_201203_112541\\\\Basler_acA1300-200uc__23039139__20201203_112543520.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat13\\\\Rat13-20201203\\\\Rat13_201203_154214\\\\Basler_acA1300-200uc__23039139__20201203_154217024.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat13\\\\Rat13-20201203\\\\Rat13_201203_164205\\\\Basler_acA1300-200uc__23039139__20201203_164208326.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat14\\\\Rat14-20201203\\\\Rat14_201203_165203\\\\Basler_acA1300-200uc__23039139__20201203_165206485.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat14\\\\Rat14-20201204\\\\Rat14_201204_113458\\\\Basler_acA1300-200uc__23039139__20201204_113501813.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat14\\\\Rat14-20201204\\\\Rat14_201204_161859\\\\Basler_acA1300-200uc__23039139__20201204_161901930.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat14\\\\Rat14-20201204\\\\Rat14_201204_172709\\\\Basler_acA1300-200uc__23039139__20201204_172711737.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat15\\\\Rat15-20201130\\\\Rat15_201130_164002\\\\Basler_acA1300-200uc__23039139__20201130_164007396.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat15\\\\Rat15-20201201\\\\Rat15_201201_114224\\\\Basler_acA1300-200uc__23039139__20201201_114229659.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat15\\\\Rat15-20201201\\\\Rat15_201201_115713\\\\Basler_acA1300-200uc__23039139__20201201_115716478.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat15\\\\Rat15-20201201\\\\Rat15_201201_155055\\\\Basler_acA1300-200uc__23039139__20201201_155058121.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat15\\\\Rat15-20201201\\\\Rat15_201201_171012\\\\Basler_acA1300-200uc__23039139__20201201_171014184.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat15\\\\Rat15-20201201\\\\Rat15_201201_171738\\\\Basler_acA1300-200uc__23039139__20201201_171741115.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat16\\\\Rat16-20201201\\\\Rat16_201201_172742\\\\Basler_acA1300-200uc__23039139__20201201_172745824.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat16\\\\Rat16-20201202\\\\Rat16_201202_132308\\\\Basler_acA1300-200uc__23039139__20201202_132311436.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat16\\\\Rat16-20201202\\\\Rat16_201202_171552\\\\Basler_acA1300-200uc__23039139__20201202_171555498.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat16\\\\Rat16-20201202\\\\Rat16_201202_182207\\\\Basler_acA1300-200uc__23039139__20201202_182209029.mp4',\n",
       " 'Y://fear_conditionning_ptsd/Rat16\\\\Rat16-20201202\\\\Rat16_201202_182329\\\\Basler_acA1300-200uc__23039139__20201202_182331883.mp4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = []\n",
    "\n",
    "for v in videos:\n",
    "    try:\n",
    "        del x,y\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cap = cv2.VideoCapture(v)\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    pause = True\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.imshow(frame)\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    \n",
    "    while pause:\n",
    "        plt.pause(0.1)\n",
    "        \n",
    "    plt.close('all')\n",
    "    crop.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([431.7077922077923, 952.5735930735934],\n",
       "  [252.72943722943705, 563.0324675324674]),\n",
       " ([578.5476190476192, 891.6212121212125],\n",
       "  [241.64718614718595, 557.4913419913419]),\n",
       " ([440.01948051948057, 960.8852813852816],\n",
       "  [252.72943722943705, 560.2619047619046])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    \n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [431, 952, 252, 563]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:\\classical_fear_conditionning\\classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "Starting to analyze %  Y://fear_conditionning_ptsd/Rat07\\Rat07-20201109\\Basler_acA1300-200uc__23039139__20201109_170654127.mp4\n",
      "Y:\\fear_conditionning_ptsd\\Rat07\\Rat07-20201109  already exists!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y://fear_conditionning_ptsd/Rat07\\Rat07-20201109\\Basler_acA1300-200uc__23039139__20201109_170654127.mp4\n",
      "Data from Basler_acA1300-200uc__23039139__20201109_170654127 were already filtered. Skipping...\n",
      "Overwriting cropping parameters: [578, 891, 241, 557]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-1030000 for model E:\\classical_fear_conditionning\\classical_fear_conditionning-BM-2020-11-20\\dlc-models\\iteration-3\\classical_fear_conditionningNov20-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-37af341dc038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze_videos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcropping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_as_csv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mdlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterpredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_as_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfiltertype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'arima'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py\u001b[0m in \u001b[0;36manalyze_videos\u001b[1;34m(config, videos, videotype, shuffle, trainingsetindex, gputouse, save_as_csv, destfolder, batchsize, cropping, get_nframesfrommetadata, TFGPUinference, dynamic, modelprefix, c_engine, robust_nframes)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;31m# sess, inputs, outputs = predict.setup_pose_prediction(dlc_cfg)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mTFGPUinference\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_GPUpose_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_pose_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlc_cfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\predict.py\u001b[0m in \u001b[0;36msetup_GPUpose_prediction\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0mnet_heads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpose_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnet_heads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pose\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\pose_net.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mAdded\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1909.11229\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[0mheads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[0mlocref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"locref\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"part_pred\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\pose_net.py\u001b[0m in \u001b[0;36mget_net\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\nnet\\pose_net.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnet_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet_arg_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 net, end_points = net_fun(\n\u001b[1;32m--> 130\u001b[1;33m                     \u001b[0mim_centered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_stride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                 )\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\nets\\resnet_v1.py\u001b[0m in \u001b[0;36mresnet_v1_50\u001b[1;34m(inputs, num_classes, is_training, global_pool, output_stride, reuse, scope)\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[0minclude_root_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m       scope=scope)\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\nets\\resnet_v1.py\u001b[0m in \u001b[0;36mresnet_v1\u001b[1;34m(inputs, blocks, num_classes, is_training, global_pool, output_stride, include_root_block, reuse, scope)\u001b[0m\n\u001b[0;32m    205\u001b[0m           \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pool1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_blocks_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_stride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mglobal_pool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m           \u001b[1;31m# Global average pooling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\nets\\resnet_utils.py\u001b[0m in \u001b[0;36mstack_blocks_dense\u001b[1;34m(net, blocks, output_stride, outputs_collections)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m             \u001b[0mcurrent_stride\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stride'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m       \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_named_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_collections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\nets\\resnet_v1.py\u001b[0m in \u001b[0;36mbottleneck\u001b[1;34m(inputs, depth, depth_bottleneck, stride, rate, outputs_collections, scope)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     residual = layers.conv2d(\n\u001b[1;32m--> 117\u001b[1;33m         inputs, depth_bottleneck, [1, 1], stride=1, scope='conv1')\n\u001b[0m\u001b[0;32m    118\u001b[0m     residual = resnet_utils.conv2d_same(\n\u001b[0;32m    119\u001b[0m         residual, depth_bottleneck, 3, stride, rate=rate, scope='conv2')\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36mconvolution2d\u001b[1;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[0;32m   1153\u001b[0m                      \u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m                      \u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1155\u001b[1;33m                      conv_dims=2)\n\u001b[0m\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[0mconvolution2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalizer_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m       \u001b[0mnormalizer_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalizer_params\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalizer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnormalizer_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mactivation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, param_regularizers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope, renorm, renorm_clipping, renorm_decay, adjustment)\u001b[0m\n\u001b[0;32m    649\u001b[0m           \u001b[0m_reuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m           fused=fused)\n\u001b[1;32m--> 651\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m       \u001b[1;31m# Add variables to collections.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \"\"\"\n\u001b[1;32m-> 1227\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1601\u001b[0m     \u001b[1;31m# Only call `build` if the user has manually overridden the build method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1602\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_default'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1603\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    373\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_variables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariableSynchronization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mON_READ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m           aggregation=tf_variables.VariableAggregation.MEAN)\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             getter=vs.get_variable)\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    350\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    605\u001b[0m     new_variable = getter(\n\u001b[0;32m    606\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1477\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1218\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    528\u001b[0m           function_utils.has_kwargs(custom_getter)):\n\u001b[0;32m    529\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"constraint\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       return _true_getter(\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mwrapped_custom_getter\u001b[1;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m     return custom_getter(\n\u001b[0;32m   1937\u001b[0m         \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_getter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1938\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   1939\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_custom_getter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[1;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1748\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rename'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1750\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[1;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, synchronization, aggregation, **_)\u001b[0m\n\u001b[0;32m   1739\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1741\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m    351\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[1;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1748\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rename'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1750\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[1;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, synchronization, aggregation, **_)\u001b[0m\n\u001b[0;32m   1739\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1741\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m    351\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    497\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    912\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store_eager_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m                         aggregation=VariableAggregation.NONE):\n\u001b[0;32m    154\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m         \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2494\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2495\u001b[1;33m         expected_shape=expected_shape, import_scope=import_scope)\n\u001b[0m\u001b[0;32m   2496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[0;32m   1393\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[0;32m   1501\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m               self._initial_value = ops.convert_to_tensor(\n\u001b[1;32m-> 1503\u001b[1;33m                   initial_value(), name=\"initial_value\", dtype=dtype)\n\u001b[0m\u001b[0;32m   1504\u001b[0m               shape = (self._initial_value.get_shape()\n\u001b[0;32m   1505\u001b[0m                        if validate_shape else tensor_shape.unknown_shape())\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m           init_val = lambda: initializer(  # pylint: disable=g-long-lambda\n\u001b[1;32m--> 883\u001b[1;33m               shape.as_list(), dtype=dtype, partition_info=partition_info)\n\u001b[0m\u001b[0;32m    884\u001b[0m           \u001b[0mvariable_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m         elif len(tf_inspect.getargspec(initializer).args) == len(\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype, partition_info)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mones\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2016\u001b[0m         \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2017\u001b[0m         \u001b[1;31m# to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2018\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2020\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   1761\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1763\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1764\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m     \u001b[1;31m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    243\u001b[0m   \"\"\"\n\u001b[0;32m    244\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 245\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    287\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[0;32m    288\u001b[0m              \"dtype\": dtype_value},\n\u001b[1;32m--> 289\u001b[1;33m       name=name).outputs[0]\n\u001b[0m\u001b[0;32m    290\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3300\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1823\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.analyze_videos(config_path,v,cropping=c,save_as_csv=True)\n",
    "    dlc.filterpredictions(config_path,v,save_as_csv = True,filtertype='arima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pickle'): metadata.append(os.path.join(subdirs,file))\n",
    "\n",
    "del metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = 'Y://fear_conditionning_ptsd/Rat16/Rat16-20201202/Rat16_201202_171552/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in videos:\n",
    "    dlc.create_labeled_video(config_path,v,filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  308  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  183.067 , recorded @  30.0 fps!\n",
      "Overall # of frames:  5492 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 183.07  seconds.\n",
      "Extracting and downsampling... 308  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308it [00:08, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [85, 4230, 1674, 51, 1848, 4507, 185, 273, 510, 2426]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat07\\Rat07-20201109\\Basler_acA1300-200uc__23039139__20201109_170654127.mp4 Coordinates for cropping: (500, 988, 194, 471)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201109_170654127.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  451  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  215.04 , recorded @  25.0 fps!\n",
      "Overall # of frames:  5376 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 215.04  seconds.\n",
      "Extracting and downsampling... 451  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "451it [00:11, 37.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [4693, 4898, 3800, 3908, 4970, 1183, 1166, 2801, 5285, 4661]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat07\\Rat07-20201109\\Rat07_201109_121627\\Basler_acA1300-200uc__23039139__20201109_121631619.mp4 Coordinates for cropping: (642, 924, 266, 543)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201109_121631619.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  23  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.167 , recorded @  30.0 fps!\n",
      "Overall # of frames:  5285 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 176.17  seconds.\n",
      "Extracting and downsampling... 23  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:01, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [1561, 3353, 884, 4229, 1492, 653, 749, 4204, 2622, 1029]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat07\\Rat07-20201109\\Rat07_201109_161952\\Basler_acA1300-200uc__23039139__20201109_161956558.mp4 Coordinates for cropping: (559, 838, 269, 557)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201109_161956558.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  35  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  157.5 , recorded @  30.0 fps!\n",
      "Overall # of frames:  4725 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 157.5  seconds.\n",
      "Extracting and downsampling... 35  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:01, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [1478, 987, 848, 3628, 3814, 4374, 3658, 3832, 442, 1139]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat08\\Rat08-20201109\\Basler_acA1300-200uc__23039139__20201109_171631263.mp4 Coordinates for cropping: (412, 919, 180, 477)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201109_171631263.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  702  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  248.534 , recorded @  30.0 fps!\n",
      "Overall # of frames:  7456 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 248.53  seconds.\n",
      "Extracting and downsampling... 702  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702it [00:18, 37.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2546, 5497, 7131, 3823, 3317, 2823, 581, 3929, 5611, 3127]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat08\\Rat08-20201110\\Rat08-20201110_201110_113809\\Basler_acA1300-200uc__23039139__20201110_113811828.mp4 Coordinates for cropping: (681, 966, 321, 623)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201110_113811828.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  888  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  248.867 , recorded @  30.0 fps!\n",
      "Overall # of frames:  7466 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 248.87  seconds.\n",
      "Extracting and downsampling... 888  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "888it [00:22, 40.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2132, 4098, 6169, 4826, 6921, 6410, 5635, 5038, 4620, 3816]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat08\\Rat08-20201110\\Rat08-20201110_201110_153156\\Basler_acA1300-200uc__23039139__20201110_153159547.mp4 Coordinates for cropping: (392, 902, 283, 565)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201110_153159547.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  787  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  248.4 , recorded @  30.0 fps!\n",
      "Overall # of frames:  7452 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 248.4  seconds.\n",
      "Extracting and downsampling... 787  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "787it [00:20, 37.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [5832, 1468, 247, 2814, 7396, 709, 4472, 3363, 2115, 2954]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat08\\Rat08-20201110\\Rat08-20201110_201110_161904\\Basler_acA1300-200uc__23039139__20201110_161906309.mp4 Coordinates for cropping: (570, 883, 211, 538)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201110_161906309.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  73  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  276.934 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8308 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 276.93  seconds.\n",
      "Extracting and downsampling... 73  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [00:03, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [420, 771, 825, 736, 768, 754, 783, 740, 738, 796]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat13\\Rat13-20201202\\Rat13_201202_183404\\Basler_acA1300-200uc__23039139__20201202_183406294.mp4 Coordinates for cropping: (456, 980, 191, 490)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201202_183406294.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  796  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  285.2 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8556 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 285.2  seconds.\n",
      "Extracting and downsampling... 796  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "796it [00:19, 39.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [4298, 753, 415, 3218, 163, 739, 316, 446, 246, 4265]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat13\\Rat13-20201203\\Rat13_201203_112541\\Basler_acA1300-200uc__23039139__20201203_112543520.mp4 Coordinates for cropping: (453, 974, 211, 485)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201203_112543520.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  331  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  263.867 , recorded @  30.0 fps!\n",
      "Overall # of frames:  7916 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 263.87  seconds.\n",
      "Extracting and downsampling... 331  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331it [00:08, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [495, 273, 448, 6642, 397, 306, 6948, 480, 7211, 328]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat13\\Rat13-20201203\\Rat13_201203_154214\\Basler_acA1300-200uc__23039139__20201203_154217024.mp4 Coordinates for cropping: (581, 886, 202, 490)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201203_154217024.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  196  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  271.934 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8158 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 271.93  seconds.\n",
      "Extracting and downsampling... 196  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [00:04, 41.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [361, 636, 503, 662, 136, 66, 168, 1107, 673, 615]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat13\\Rat13-20201203\\Rat13_201203_164205\\Basler_acA1300-200uc__23039139__20201203_164208326.mp4 Coordinates for cropping: (584, 897, 197, 504)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201203_164208326.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  109  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  264.9 , recorded @  30.0 fps!\n",
      "Overall # of frames:  7947 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 264.9  seconds.\n",
      "Extracting and downsampling... 109  frames from the video."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:02, 37.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [4138, 7, 475, 212, 445, 326, 464, 487, 510, 133]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat14\\Rat14-20201203\\Rat14_201203_165203\\Basler_acA1300-200uc__23039139__20201203_165206485.mp4 Coordinates for cropping: (431, 952, 252, 563)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201203_165206485.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1045  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  301.834 , recorded @  30.0 fps!\n",
      "Overall # of frames:  9055 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 301.83  seconds.\n",
      "Extracting and downsampling... 1045  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1045it [00:26, 39.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [4839, 1065, 367, 1358, 1511, 146, 516, 8429, 2080, 1552]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat14\\Rat14-20201204\\Rat14_201204_113458\\Basler_acA1300-200uc__23039139__20201204_113501813.mp4 Coordinates for cropping: (578, 891, 241, 557)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201204_113501813.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  177  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  273.6 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8208 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 273.6  seconds.\n",
      "Extracting and downsampling... 177  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "177it [00:04, 38.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [520, 2904, 231, 666, 143, 294, 592, 379, 498, 696]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat14\\Rat14-20201204\\Rat14_201204_161859\\Basler_acA1300-200uc__23039139__20201204_161901930.mp4 Coordinates for cropping: (440, 960, 252, 560)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201204_161901930.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  394  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  271.234 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8137 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 271.23  seconds.\n",
      "Extracting and downsampling... 394  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "394it [00:09, 39.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [677, 242, 748, 11, 156, 694, 626, 614, 451, 489]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat14\\Rat14-20201204\\Rat14_201204_172709\\Basler_acA1300-200uc__23039139__20201204_172711737.mp4 Coordinates for cropping: (559, 874, 166, 468)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201204_172711737.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  113  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273.134 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8194 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 273.13  seconds.\n",
      "Extracting and downsampling... 113  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [00:03, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [41, 5500, 718, 740, 724, 697, 708, 696, 736, 702]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat15\\Rat15-20201130\\Rat15_201130_164002\\Basler_acA1300-200uc__23039139__20201130_164007396.mp4 Coordinates for cropping: (459, 974, 230, 513)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201130_164007396.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  534  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  150.967 , recorded @  30.0 fps!\n",
      "Overall # of frames:  4529 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 150.97  seconds.\n",
      "Extracting and downsampling... 534  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "534it [00:13, 40.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [896, 19, 870, 253, 749, 4378, 665, 304, 342, 877]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat15\\Rat15-20201201\\Rat15_201201_114224\\Basler_acA1300-200uc__23039139__20201201_114229659.mp4 Coordinates for cropping: (462, 969, 227, 521)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201201_114229659.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  858  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  315.167 , recorded @  30.0 fps!\n",
      "Overall # of frames:  9455 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 315.17  seconds.\n",
      "Extracting and downsampling... 858  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "858it [00:21, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [625, 5290, 320, 493, 604, 795, 39, 814, 878, 763]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat15\\Rat15-20201201\\Rat15_201201_115713\\Basler_acA1300-200uc__23039139__20201201_115716478.mp4 Coordinates for cropping: (448, 985, 216, 515)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201201_115716478.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  728  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 19.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  287.867 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8636 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 287.87  seconds.\n",
      "Extracting and downsampling... 728  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:17, 42.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [370, 84, 349, 1000, 1019, 851, 298, 1075, 836, 211]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat15\\Rat15-20201201\\Rat15_201201_155055\\Basler_acA1300-200uc__23039139__20201201_155058121.mp4 Coordinates for cropping: (561, 869, 233, 532)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201201_155058121.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  465  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  138.3 , recorded @  30.0 fps!\n",
      "Overall # of frames:  4149 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 138.3  seconds.\n",
      "Extracting and downsampling... 465  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "465it [00:11, 40.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [3596, 3250, 614, 713, 690, 3027, 3259, 681, 667, 3441]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat15\\Rat15-20201201\\Rat15_201201_171012\\Basler_acA1300-200uc__23039139__20201201_171014184.mp4 Coordinates for cropping: (556, 863, 238, 538)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201201_171014184.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  933  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  109.0 , recorded @  30.0 fps!\n",
      "Overall # of frames:  3270 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 109.0  seconds.\n",
      "Extracting and downsampling... 933  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "933it [00:22, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2099, 1957, 660, 2571, 2469, 1440, 2081, 947, 1851, 2527]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat15\\Rat15-20201201\\Rat15_201201_171738\\Basler_acA1300-200uc__23039139__20201201_171741115.mp4 Coordinates for cropping: (553, 877, 219, 524)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201201_171741115.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  248  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  272.734 , recorded @  30.0 fps!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 27.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall # of frames:  8182 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 272.73  seconds.\n",
      "Extracting and downsampling... 248  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [00:06, 39.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [495, 592, 238, 653, 2725, 715, 510, 690, 168, 679]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat16\\Rat16-20201201\\Rat16_201201_172742\\Basler_acA1300-200uc__23039139__20201201_172745824.mp4 Coordinates for cropping: (456, 988, 213, 513)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201201_172745824.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1186  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  275.4 , recorded @  30.0 fps!\n",
      "Overall # of frames:  8262 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 275.4  seconds.\n",
      "Extracting and downsampling... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 16.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1186it [00:29, 40.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [3472, 168, 619, 92, 6499, 273, 804, 7366, 531, 393]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat16\\Rat16-20201202\\Rat16_201202_132308\\Basler_acA1300-200uc__23039139__20201202_132311436.mp4 Coordinates for cropping: (448, 971, 213, 490)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201202_132311436.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  333  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  263.9 , recorded @  30.0 fps!\n",
      "Overall # of frames:  7917 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 263.9  seconds.\n",
      "Extracting and downsampling... 333  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "333it [00:08, 39.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [7511, 183, 316, 274, 361, 14, 483, 339, 399, 301]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat16\\Rat16-20201202\\Rat16_201202_171552\\Basler_acA1300-200uc__23039139__20201202_171555498.mp4 Coordinates for cropping: (573, 886, 230, 527)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201202_171555498.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  39  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video...\n",
      "Duration of video [s]:  49.634 , recorded @  30.0 fps!\n",
      "Overall # of frames:  1489 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 49.63  seconds.\n",
      "Extracting and downsampling... 39  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:01, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [269, 287, 112, 298, 274, 362, 289, 275, 280, 270]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y://fear_conditionning_ptsd/Rat16\\Rat16-20201202\\Rat16_201202_182207\\Basler_acA1300-200uc__23039139__20201202_182209029.mp4 Coordinates for cropping: (567, 872, 216, 529)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201202_182209029.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    \n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    \n",
    "    dlc.extract_outlier_frames(config_path,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['snout', 'left_ear', 'right_ear', 'b_tail', 'e_tail'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\elevated_plus_maze_Maelle95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\maelle.christiaens\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01\\\\dlc-models\\\\iteration-4\\\\elevated_plus_mazeDec01-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_elevated_plus_mazeDec01shuffle1_1030000  with # of trainingiterations: 1030000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130it [00:16,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-1030000\n",
      "Results for 1030000  training iterations: 95 1 train error: 1.49 pixels. Test error: 6.91  pixels.\n",
      "With pcutoff of 0.1  train error: 1.49 pixels. Test error: 3.75 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "dlc.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 4.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 78,  23,  57,  63, 106,   4, 102,  85,  66,   8,  21,  52, 119,\n",
       "           37, 123, 122, 109, 126, 100,  69,  26,  70,  84,  65,  18, 124,\n",
       "           83,  30,  40,  14,  47,   5, 104, 128,  33,  34,  44,  76,  25,\n",
       "            2,  38,   1,  68,  77,   6,  93,  96,  92,  32, 113,  43, 101,\n",
       "           42,  59,  31, 116, 114,  15,  67,  94,   3,  22,  58,  75,  48,\n",
       "           27,  13,  88,  41,  28,   0,   7, 107,  81, 117,  71, 121,  20,\n",
       "           53, 103,   9,  10,  61,  54,  45,  46,  50, 105,  89,  36,  97,\n",
       "           95,  24,  72,  51,  91,  90,  11,  35,  12,  19, 120, 115, 112,\n",
       "           64,  17,  87,  39,  74,  60,  86, 129,  29,  16, 118, 111,  80,\n",
       "           56, 127,  98, 110,  79, 125]),\n",
       "   array([ 49, 108,  99,  62,  82,  55,  73])))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['snout', 'left_ear', 'right_ear', 'b_tail', 'e_tail'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\elevated_plus_maze_Maelle95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\maelle.christiaens\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\Documentation_data-elevated_plus_maze_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01\\\\dlc-models\\\\iteration-4\\\\elevated_plus_mazeDec01-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01\\\\dlc-models\\\\iteration-4\\\\elevated_plus_mazeDec01-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4]], 'all_joints_names': ['snout', 'left_ear', 'right_ear', 'b_tail', 'e_tail'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\elevated_plus_maze_Maelle95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\maelle.christiaens\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\Documentation_data-elevated_plus_maze_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 5, 'pos_dist_thresh': 17, 'project_path': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0299 lr: 0.005\n",
      "iteration: 2000 loss: 0.0220 lr: 0.005\n",
      "iteration: 3000 loss: 0.0185 lr: 0.005\n",
      "iteration: 4000 loss: 0.0156 lr: 0.005\n",
      "iteration: 5000 loss: 0.0138 lr: 0.005\n",
      "iteration: 6000 loss: 0.0126 lr: 0.005\n",
      "iteration: 7000 loss: 0.0113 lr: 0.005\n",
      "iteration: 8000 loss: 0.0103 lr: 0.005\n",
      "iteration: 9000 loss: 0.0097 lr: 0.005\n",
      "iteration: 10000 loss: 0.0093 lr: 0.005\n",
      "iteration: 11000 loss: 0.0126 lr: 0.02\n",
      "iteration: 12000 loss: 0.0104 lr: 0.02\n",
      "iteration: 13000 loss: 0.0088 lr: 0.02\n",
      "iteration: 14000 loss: 0.0079 lr: 0.02\n",
      "iteration: 15000 loss: 0.0071 lr: 0.02\n",
      "iteration: 16000 loss: 0.0065 lr: 0.02\n",
      "iteration: 17000 loss: 0.0060 lr: 0.02\n",
      "iteration: 18000 loss: 0.0058 lr: 0.02\n",
      "iteration: 19000 loss: 0.0052 lr: 0.02\n",
      "iteration: 20000 loss: 0.0050 lr: 0.02\n",
      "iteration: 21000 loss: 0.0049 lr: 0.02\n",
      "iteration: 22000 loss: 0.0046 lr: 0.02\n",
      "iteration: 23000 loss: 0.0045 lr: 0.02\n",
      "iteration: 24000 loss: 0.0045 lr: 0.02\n",
      "iteration: 25000 loss: 0.0042 lr: 0.02\n",
      "iteration: 26000 loss: 0.0042 lr: 0.02\n",
      "iteration: 27000 loss: 0.0039 lr: 0.02\n",
      "iteration: 28000 loss: 0.0037 lr: 0.02\n",
      "iteration: 29000 loss: 0.0038 lr: 0.02\n",
      "iteration: 30000 loss: 0.0038 lr: 0.02\n",
      "iteration: 31000 loss: 0.0039 lr: 0.02\n",
      "iteration: 32000 loss: 0.0036 lr: 0.02\n",
      "iteration: 33000 loss: 0.0036 lr: 0.02\n",
      "iteration: 34000 loss: 0.0033 lr: 0.02\n",
      "iteration: 35000 loss: 0.0035 lr: 0.02\n",
      "iteration: 36000 loss: 0.0033 lr: 0.02\n",
      "iteration: 37000 loss: 0.0033 lr: 0.02\n",
      "iteration: 38000 loss: 0.0033 lr: 0.02\n",
      "iteration: 39000 loss: 0.0032 lr: 0.02\n",
      "iteration: 40000 loss: 0.0032 lr: 0.02\n",
      "iteration: 41000 loss: 0.0033 lr: 0.02\n",
      "iteration: 42000 loss: 0.0031 lr: 0.02\n",
      "iteration: 43000 loss: 0.0031 lr: 0.02\n",
      "iteration: 44000 loss: 0.0030 lr: 0.02\n",
      "iteration: 45000 loss: 0.0031 lr: 0.02\n",
      "iteration: 46000 loss: 0.0030 lr: 0.02\n",
      "iteration: 47000 loss: 0.0029 lr: 0.02\n",
      "iteration: 48000 loss: 0.0029 lr: 0.02\n",
      "iteration: 49000 loss: 0.0029 lr: 0.02\n",
      "iteration: 50000 loss: 0.0028 lr: 0.02\n",
      "iteration: 51000 loss: 0.0029 lr: 0.02\n",
      "iteration: 52000 loss: 0.0027 lr: 0.02\n",
      "iteration: 53000 loss: 0.0028 lr: 0.02\n",
      "iteration: 54000 loss: 0.0028 lr: 0.02\n",
      "iteration: 55000 loss: 0.0028 lr: 0.02\n",
      "iteration: 56000 loss: 0.0026 lr: 0.02\n",
      "iteration: 57000 loss: 0.0028 lr: 0.02\n",
      "iteration: 58000 loss: 0.0027 lr: 0.02\n",
      "iteration: 59000 loss: 0.0026 lr: 0.02\n",
      "iteration: 60000 loss: 0.0027 lr: 0.02\n",
      "iteration: 61000 loss: 0.0026 lr: 0.02\n",
      "iteration: 62000 loss: 0.0026 lr: 0.02\n",
      "iteration: 63000 loss: 0.0026 lr: 0.02\n",
      "iteration: 64000 loss: 0.0025 lr: 0.02\n",
      "iteration: 65000 loss: 0.0025 lr: 0.02\n",
      "iteration: 66000 loss: 0.0026 lr: 0.02\n",
      "iteration: 67000 loss: 0.0026 lr: 0.02\n",
      "iteration: 68000 loss: 0.0026 lr: 0.02\n",
      "iteration: 69000 loss: 0.0025 lr: 0.02\n",
      "iteration: 70000 loss: 0.0025 lr: 0.02\n",
      "iteration: 71000 loss: 0.0025 lr: 0.02\n",
      "iteration: 72000 loss: 0.0024 lr: 0.02\n",
      "iteration: 73000 loss: 0.0024 lr: 0.02\n",
      "iteration: 74000 loss: 0.0025 lr: 0.02\n",
      "iteration: 75000 loss: 0.0025 lr: 0.02\n",
      "iteration: 76000 loss: 0.0024 lr: 0.02\n",
      "iteration: 77000 loss: 0.0024 lr: 0.02\n",
      "iteration: 78000 loss: 0.0024 lr: 0.02\n",
      "iteration: 79000 loss: 0.0024 lr: 0.02\n",
      "iteration: 80000 loss: 0.0024 lr: 0.02\n",
      "iteration: 81000 loss: 0.0023 lr: 0.02\n",
      "iteration: 82000 loss: 0.0024 lr: 0.02\n",
      "iteration: 83000 loss: 0.0024 lr: 0.02\n",
      "iteration: 84000 loss: 0.0023 lr: 0.02\n",
      "iteration: 85000 loss: 0.0023 lr: 0.02\n",
      "iteration: 86000 loss: 0.0024 lr: 0.02\n",
      "iteration: 87000 loss: 0.0023 lr: 0.02\n",
      "iteration: 88000 loss: 0.0023 lr: 0.02\n",
      "iteration: 89000 loss: 0.0023 lr: 0.02\n",
      "iteration: 90000 loss: 0.0023 lr: 0.02\n",
      "iteration: 91000 loss: 0.0023 lr: 0.02\n",
      "iteration: 92000 loss: 0.0022 lr: 0.02\n",
      "iteration: 93000 loss: 0.0023 lr: 0.02\n",
      "iteration: 94000 loss: 0.0024 lr: 0.02\n",
      "iteration: 95000 loss: 0.0023 lr: 0.02\n",
      "iteration: 96000 loss: 0.0022 lr: 0.02\n",
      "iteration: 97000 loss: 0.0022 lr: 0.02\n",
      "iteration: 98000 loss: 0.0023 lr: 0.02\n",
      "iteration: 99000 loss: 0.0022 lr: 0.02\n",
      "iteration: 100000 loss: 0.0022 lr: 0.02\n",
      "iteration: 101000 loss: 0.0022 lr: 0.02\n",
      "iteration: 102000 loss: 0.0023 lr: 0.02\n",
      "iteration: 103000 loss: 0.0022 lr: 0.02\n",
      "iteration: 104000 loss: 0.0022 lr: 0.02\n",
      "iteration: 105000 loss: 0.0022 lr: 0.02\n",
      "iteration: 106000 loss: 0.0022 lr: 0.02\n",
      "iteration: 107000 loss: 0.0023 lr: 0.02\n",
      "iteration: 108000 loss: 0.0022 lr: 0.02\n",
      "iteration: 109000 loss: 0.0022 lr: 0.02\n",
      "iteration: 110000 loss: 0.0021 lr: 0.02\n",
      "iteration: 111000 loss: 0.0022 lr: 0.02\n",
      "iteration: 112000 loss: 0.0021 lr: 0.02\n",
      "iteration: 113000 loss: 0.0021 lr: 0.02\n",
      "iteration: 114000 loss: 0.0021 lr: 0.02\n",
      "iteration: 115000 loss: 0.0021 lr: 0.02\n",
      "iteration: 116000 loss: 0.0021 lr: 0.02\n",
      "iteration: 117000 loss: 0.0021 lr: 0.02\n",
      "iteration: 118000 loss: 0.0021 lr: 0.02\n",
      "iteration: 119000 loss: 0.0021 lr: 0.02\n",
      "iteration: 120000 loss: 0.0021 lr: 0.02\n",
      "iteration: 121000 loss: 0.0021 lr: 0.02\n",
      "iteration: 122000 loss: 0.0021 lr: 0.02\n",
      "iteration: 123000 loss: 0.0021 lr: 0.02\n",
      "iteration: 124000 loss: 0.0021 lr: 0.02\n",
      "iteration: 125000 loss: 0.0021 lr: 0.02\n",
      "iteration: 126000 loss: 0.0021 lr: 0.02\n",
      "iteration: 127000 loss: 0.0021 lr: 0.02\n",
      "iteration: 128000 loss: 0.0021 lr: 0.02\n",
      "iteration: 129000 loss: 0.0021 lr: 0.02\n",
      "iteration: 130000 loss: 0.0021 lr: 0.02\n",
      "iteration: 131000 loss: 0.0021 lr: 0.02\n",
      "iteration: 132000 loss: 0.0021 lr: 0.02\n",
      "iteration: 133000 loss: 0.0021 lr: 0.02\n",
      "iteration: 134000 loss: 0.0022 lr: 0.02\n",
      "iteration: 135000 loss: 0.0021 lr: 0.02\n",
      "iteration: 136000 loss: 0.0021 lr: 0.02\n",
      "iteration: 137000 loss: 0.0020 lr: 0.02\n",
      "iteration: 138000 loss: 0.0020 lr: 0.02\n",
      "iteration: 139000 loss: 0.0021 lr: 0.02\n",
      "iteration: 140000 loss: 0.0021 lr: 0.02\n",
      "iteration: 141000 loss: 0.0020 lr: 0.02\n",
      "iteration: 142000 loss: 0.0021 lr: 0.02\n",
      "iteration: 143000 loss: 0.0020 lr: 0.02\n",
      "iteration: 144000 loss: 0.0020 lr: 0.02\n",
      "iteration: 145000 loss: 0.0021 lr: 0.02\n",
      "iteration: 146000 loss: 0.0020 lr: 0.02\n",
      "iteration: 147000 loss: 0.0020 lr: 0.02\n",
      "iteration: 148000 loss: 0.0020 lr: 0.02\n",
      "iteration: 149000 loss: 0.0020 lr: 0.02\n",
      "iteration: 150000 loss: 0.0020 lr: 0.02\n",
      "iteration: 151000 loss: 0.0020 lr: 0.02\n",
      "iteration: 152000 loss: 0.0020 lr: 0.02\n",
      "iteration: 153000 loss: 0.0019 lr: 0.02\n",
      "iteration: 154000 loss: 0.0019 lr: 0.02\n",
      "iteration: 155000 loss: 0.0020 lr: 0.02\n",
      "iteration: 156000 loss: 0.0019 lr: 0.02\n",
      "iteration: 157000 loss: 0.0019 lr: 0.02\n",
      "iteration: 158000 loss: 0.0020 lr: 0.02\n",
      "iteration: 159000 loss: 0.0020 lr: 0.02\n",
      "iteration: 160000 loss: 0.0019 lr: 0.02\n",
      "iteration: 161000 loss: 0.0020 lr: 0.02\n",
      "iteration: 162000 loss: 0.0019 lr: 0.02\n",
      "iteration: 163000 loss: 0.0019 lr: 0.02\n",
      "iteration: 164000 loss: 0.0019 lr: 0.02\n",
      "iteration: 165000 loss: 0.0020 lr: 0.02\n",
      "iteration: 166000 loss: 0.0019 lr: 0.02\n",
      "iteration: 167000 loss: 0.0020 lr: 0.02\n",
      "iteration: 168000 loss: 0.0020 lr: 0.02\n",
      "iteration: 169000 loss: 0.0019 lr: 0.02\n",
      "iteration: 170000 loss: 0.0019 lr: 0.02\n",
      "iteration: 171000 loss: 0.0020 lr: 0.02\n",
      "iteration: 172000 loss: 0.0020 lr: 0.02\n",
      "iteration: 173000 loss: 0.0019 lr: 0.02\n",
      "iteration: 174000 loss: 0.0019 lr: 0.02\n",
      "iteration: 175000 loss: 0.0019 lr: 0.02\n",
      "iteration: 176000 loss: 0.0019 lr: 0.02\n",
      "iteration: 177000 loss: 0.0019 lr: 0.02\n",
      "iteration: 178000 loss: 0.0019 lr: 0.02\n",
      "iteration: 179000 loss: 0.0019 lr: 0.02\n",
      "iteration: 180000 loss: 0.0019 lr: 0.02\n",
      "iteration: 181000 loss: 0.0019 lr: 0.02\n",
      "iteration: 182000 loss: 0.0019 lr: 0.02\n",
      "iteration: 183000 loss: 0.0019 lr: 0.02\n",
      "iteration: 184000 loss: 0.0019 lr: 0.02\n",
      "iteration: 185000 loss: 0.0019 lr: 0.02\n",
      "iteration: 186000 loss: 0.0019 lr: 0.02\n",
      "iteration: 187000 loss: 0.0019 lr: 0.02\n",
      "iteration: 188000 loss: 0.0019 lr: 0.02\n",
      "iteration: 189000 loss: 0.0019 lr: 0.02\n",
      "iteration: 190000 loss: 0.0019 lr: 0.02\n",
      "iteration: 191000 loss: 0.0019 lr: 0.02\n",
      "iteration: 192000 loss: 0.0019 lr: 0.02\n",
      "iteration: 193000 loss: 0.0018 lr: 0.02\n",
      "iteration: 194000 loss: 0.0019 lr: 0.02\n",
      "iteration: 195000 loss: 0.0019 lr: 0.02\n",
      "iteration: 196000 loss: 0.0018 lr: 0.02\n",
      "iteration: 197000 loss: 0.0018 lr: 0.02\n",
      "iteration: 198000 loss: 0.0019 lr: 0.02\n",
      "iteration: 199000 loss: 0.0019 lr: 0.02\n",
      "iteration: 200000 loss: 0.0019 lr: 0.02\n",
      "iteration: 201000 loss: 0.0019 lr: 0.02\n",
      "iteration: 202000 loss: 0.0019 lr: 0.02\n",
      "iteration: 203000 loss: 0.0019 lr: 0.02\n",
      "iteration: 204000 loss: 0.0019 lr: 0.02\n",
      "iteration: 205000 loss: 0.0018 lr: 0.02\n",
      "iteration: 206000 loss: 0.0019 lr: 0.02\n",
      "iteration: 207000 loss: 0.0019 lr: 0.02\n",
      "iteration: 208000 loss: 0.0018 lr: 0.02\n",
      "iteration: 209000 loss: 0.0018 lr: 0.02\n",
      "iteration: 210000 loss: 0.0018 lr: 0.02\n",
      "iteration: 211000 loss: 0.0018 lr: 0.02\n",
      "iteration: 212000 loss: 0.0019 lr: 0.02\n",
      "iteration: 213000 loss: 0.0018 lr: 0.02\n",
      "iteration: 214000 loss: 0.0018 lr: 0.02\n",
      "iteration: 215000 loss: 0.0019 lr: 0.02\n",
      "iteration: 216000 loss: 0.0018 lr: 0.02\n",
      "iteration: 217000 loss: 0.0019 lr: 0.02\n",
      "iteration: 218000 loss: 0.0018 lr: 0.02\n",
      "iteration: 219000 loss: 0.0019 lr: 0.02\n",
      "iteration: 220000 loss: 0.0018 lr: 0.02\n",
      "iteration: 221000 loss: 0.0019 lr: 0.02\n",
      "iteration: 222000 loss: 0.0018 lr: 0.02\n",
      "iteration: 223000 loss: 0.0018 lr: 0.02\n",
      "iteration: 224000 loss: 0.0018 lr: 0.02\n",
      "iteration: 225000 loss: 0.0019 lr: 0.02\n",
      "iteration: 226000 loss: 0.0018 lr: 0.02\n",
      "iteration: 227000 loss: 0.0018 lr: 0.02\n",
      "iteration: 228000 loss: 0.0018 lr: 0.02\n",
      "iteration: 229000 loss: 0.0018 lr: 0.02\n",
      "iteration: 230000 loss: 0.0019 lr: 0.02\n",
      "iteration: 231000 loss: 0.0018 lr: 0.02\n",
      "iteration: 232000 loss: 0.0018 lr: 0.02\n",
      "iteration: 233000 loss: 0.0019 lr: 0.02\n",
      "iteration: 234000 loss: 0.0018 lr: 0.02\n",
      "iteration: 235000 loss: 0.0018 lr: 0.02\n",
      "iteration: 236000 loss: 0.0018 lr: 0.02\n",
      "iteration: 237000 loss: 0.0018 lr: 0.02\n",
      "iteration: 238000 loss: 0.0018 lr: 0.02\n",
      "iteration: 239000 loss: 0.0018 lr: 0.02\n",
      "iteration: 240000 loss: 0.0018 lr: 0.02\n",
      "iteration: 241000 loss: 0.0019 lr: 0.02\n",
      "iteration: 242000 loss: 0.0017 lr: 0.02\n",
      "iteration: 243000 loss: 0.0018 lr: 0.02\n",
      "iteration: 244000 loss: 0.0018 lr: 0.02\n",
      "iteration: 245000 loss: 0.0018 lr: 0.02\n",
      "iteration: 246000 loss: 0.0018 lr: 0.02\n",
      "iteration: 247000 loss: 0.0018 lr: 0.02\n",
      "iteration: 248000 loss: 0.0017 lr: 0.02\n",
      "iteration: 249000 loss: 0.0018 lr: 0.02\n",
      "iteration: 250000 loss: 0.0018 lr: 0.02\n",
      "iteration: 251000 loss: 0.0018 lr: 0.02\n",
      "iteration: 252000 loss: 0.0018 lr: 0.02\n",
      "iteration: 253000 loss: 0.0018 lr: 0.02\n",
      "iteration: 254000 loss: 0.0017 lr: 0.02\n",
      "iteration: 255000 loss: 0.0018 lr: 0.02\n",
      "iteration: 256000 loss: 0.0018 lr: 0.02\n",
      "iteration: 257000 loss: 0.0018 lr: 0.02\n",
      "iteration: 258000 loss: 0.0018 lr: 0.02\n",
      "iteration: 259000 loss: 0.0018 lr: 0.02\n",
      "iteration: 260000 loss: 0.0018 lr: 0.02\n",
      "iteration: 261000 loss: 0.0017 lr: 0.02\n",
      "iteration: 262000 loss: 0.0018 lr: 0.02\n",
      "iteration: 263000 loss: 0.0017 lr: 0.02\n",
      "iteration: 264000 loss: 0.0018 lr: 0.02\n",
      "iteration: 265000 loss: 0.0018 lr: 0.02\n",
      "iteration: 266000 loss: 0.0017 lr: 0.02\n",
      "iteration: 267000 loss: 0.0018 lr: 0.02\n",
      "iteration: 268000 loss: 0.0018 lr: 0.02\n",
      "iteration: 269000 loss: 0.0018 lr: 0.02\n",
      "iteration: 270000 loss: 0.0018 lr: 0.02\n",
      "iteration: 271000 loss: 0.0018 lr: 0.02\n",
      "iteration: 272000 loss: 0.0017 lr: 0.02\n",
      "iteration: 273000 loss: 0.0018 lr: 0.02\n",
      "iteration: 274000 loss: 0.0018 lr: 0.02\n",
      "iteration: 275000 loss: 0.0017 lr: 0.02\n",
      "iteration: 276000 loss: 0.0018 lr: 0.02\n",
      "iteration: 277000 loss: 0.0018 lr: 0.02\n",
      "iteration: 278000 loss: 0.0017 lr: 0.02\n",
      "iteration: 279000 loss: 0.0017 lr: 0.02\n",
      "iteration: 280000 loss: 0.0018 lr: 0.02\n",
      "iteration: 281000 loss: 0.0017 lr: 0.02\n",
      "iteration: 282000 loss: 0.0018 lr: 0.02\n",
      "iteration: 283000 loss: 0.0018 lr: 0.02\n",
      "iteration: 284000 loss: 0.0018 lr: 0.02\n",
      "iteration: 285000 loss: 0.0018 lr: 0.02\n",
      "iteration: 286000 loss: 0.0017 lr: 0.02\n",
      "iteration: 287000 loss: 0.0017 lr: 0.02\n",
      "iteration: 288000 loss: 0.0018 lr: 0.02\n",
      "iteration: 289000 loss: 0.0018 lr: 0.02\n",
      "iteration: 290000 loss: 0.0017 lr: 0.02\n",
      "iteration: 291000 loss: 0.0018 lr: 0.02\n",
      "iteration: 292000 loss: 0.0018 lr: 0.02\n",
      "iteration: 293000 loss: 0.0018 lr: 0.02\n",
      "iteration: 294000 loss: 0.0018 lr: 0.02\n",
      "iteration: 295000 loss: 0.0018 lr: 0.02\n",
      "iteration: 296000 loss: 0.0017 lr: 0.02\n",
      "iteration: 297000 loss: 0.0017 lr: 0.02\n",
      "iteration: 298000 loss: 0.0017 lr: 0.02\n",
      "iteration: 299000 loss: 0.0018 lr: 0.02\n",
      "iteration: 300000 loss: 0.0017 lr: 0.02\n",
      "iteration: 301000 loss: 0.0017 lr: 0.02\n",
      "iteration: 302000 loss: 0.0017 lr: 0.02\n",
      "iteration: 303000 loss: 0.0018 lr: 0.02\n",
      "iteration: 304000 loss: 0.0018 lr: 0.02\n",
      "iteration: 305000 loss: 0.0018 lr: 0.02\n",
      "iteration: 306000 loss: 0.0017 lr: 0.02\n",
      "iteration: 307000 loss: 0.0017 lr: 0.02\n",
      "iteration: 308000 loss: 0.0018 lr: 0.02\n",
      "iteration: 309000 loss: 0.0017 lr: 0.02\n",
      "iteration: 310000 loss: 0.0018 lr: 0.02\n",
      "iteration: 311000 loss: 0.0017 lr: 0.02\n",
      "iteration: 312000 loss: 0.0017 lr: 0.02\n",
      "iteration: 313000 loss: 0.0017 lr: 0.02\n",
      "iteration: 314000 loss: 0.0018 lr: 0.02\n",
      "iteration: 315000 loss: 0.0017 lr: 0.02\n",
      "iteration: 316000 loss: 0.0017 lr: 0.02\n",
      "iteration: 317000 loss: 0.0017 lr: 0.02\n",
      "iteration: 318000 loss: 0.0017 lr: 0.02\n",
      "iteration: 319000 loss: 0.0018 lr: 0.02\n",
      "iteration: 320000 loss: 0.0017 lr: 0.02\n",
      "iteration: 321000 loss: 0.0017 lr: 0.02\n",
      "iteration: 322000 loss: 0.0017 lr: 0.02\n",
      "iteration: 323000 loss: 0.0017 lr: 0.02\n",
      "iteration: 324000 loss: 0.0017 lr: 0.02\n",
      "iteration: 325000 loss: 0.0017 lr: 0.02\n",
      "iteration: 326000 loss: 0.0017 lr: 0.02\n",
      "iteration: 327000 loss: 0.0017 lr: 0.02\n",
      "iteration: 328000 loss: 0.0017 lr: 0.02\n",
      "iteration: 329000 loss: 0.0017 lr: 0.02\n",
      "iteration: 330000 loss: 0.0017 lr: 0.02\n",
      "iteration: 331000 loss: 0.0017 lr: 0.02\n",
      "iteration: 332000 loss: 0.0017 lr: 0.02\n",
      "iteration: 333000 loss: 0.0017 lr: 0.02\n",
      "iteration: 334000 loss: 0.0017 lr: 0.02\n",
      "iteration: 335000 loss: 0.0017 lr: 0.02\n",
      "iteration: 336000 loss: 0.0017 lr: 0.02\n",
      "iteration: 337000 loss: 0.0017 lr: 0.02\n",
      "iteration: 338000 loss: 0.0017 lr: 0.02\n",
      "iteration: 339000 loss: 0.0016 lr: 0.02\n",
      "iteration: 340000 loss: 0.0017 lr: 0.02\n",
      "iteration: 341000 loss: 0.0017 lr: 0.02\n",
      "iteration: 342000 loss: 0.0017 lr: 0.02\n",
      "iteration: 343000 loss: 0.0016 lr: 0.02\n",
      "iteration: 344000 loss: 0.0017 lr: 0.02\n",
      "iteration: 345000 loss: 0.0017 lr: 0.02\n",
      "iteration: 346000 loss: 0.0017 lr: 0.02\n",
      "iteration: 347000 loss: 0.0017 lr: 0.02\n",
      "iteration: 348000 loss: 0.0017 lr: 0.02\n",
      "iteration: 349000 loss: 0.0017 lr: 0.02\n",
      "iteration: 350000 loss: 0.0017 lr: 0.02\n",
      "iteration: 351000 loss: 0.0017 lr: 0.02\n",
      "iteration: 352000 loss: 0.0017 lr: 0.02\n",
      "iteration: 353000 loss: 0.0017 lr: 0.02\n",
      "iteration: 354000 loss: 0.0017 lr: 0.02\n",
      "iteration: 355000 loss: 0.0017 lr: 0.02\n",
      "iteration: 356000 loss: 0.0017 lr: 0.02\n",
      "iteration: 357000 loss: 0.0017 lr: 0.02\n",
      "iteration: 358000 loss: 0.0017 lr: 0.02\n",
      "iteration: 359000 loss: 0.0017 lr: 0.02\n",
      "iteration: 360000 loss: 0.0017 lr: 0.02\n",
      "iteration: 361000 loss: 0.0017 lr: 0.02\n",
      "iteration: 362000 loss: 0.0017 lr: 0.02\n",
      "iteration: 363000 loss: 0.0017 lr: 0.02\n",
      "iteration: 364000 loss: 0.0016 lr: 0.02\n",
      "iteration: 365000 loss: 0.0017 lr: 0.02\n",
      "iteration: 366000 loss: 0.0017 lr: 0.02\n",
      "iteration: 367000 loss: 0.0017 lr: 0.02\n",
      "iteration: 368000 loss: 0.0016 lr: 0.02\n",
      "iteration: 369000 loss: 0.0017 lr: 0.02\n",
      "iteration: 370000 loss: 0.0017 lr: 0.02\n",
      "iteration: 371000 loss: 0.0017 lr: 0.02\n",
      "iteration: 372000 loss: 0.0017 lr: 0.02\n",
      "iteration: 373000 loss: 0.0017 lr: 0.02\n",
      "iteration: 374000 loss: 0.0017 lr: 0.02\n",
      "iteration: 375000 loss: 0.0017 lr: 0.02\n",
      "iteration: 376000 loss: 0.0017 lr: 0.02\n",
      "iteration: 377000 loss: 0.0016 lr: 0.02\n",
      "iteration: 378000 loss: 0.0017 lr: 0.02\n",
      "iteration: 379000 loss: 0.0017 lr: 0.02\n",
      "iteration: 380000 loss: 0.0017 lr: 0.02\n",
      "iteration: 381000 loss: 0.0017 lr: 0.02\n",
      "iteration: 382000 loss: 0.0017 lr: 0.02\n",
      "iteration: 383000 loss: 0.0017 lr: 0.02\n",
      "iteration: 384000 loss: 0.0017 lr: 0.02\n",
      "iteration: 385000 loss: 0.0017 lr: 0.02\n",
      "iteration: 386000 loss: 0.0017 lr: 0.02\n",
      "iteration: 387000 loss: 0.0017 lr: 0.02\n",
      "iteration: 388000 loss: 0.0017 lr: 0.02\n",
      "iteration: 389000 loss: 0.0016 lr: 0.02\n",
      "iteration: 390000 loss: 0.0017 lr: 0.02\n",
      "iteration: 391000 loss: 0.0017 lr: 0.02\n",
      "iteration: 392000 loss: 0.0017 lr: 0.02\n",
      "iteration: 393000 loss: 0.0017 lr: 0.02\n",
      "iteration: 394000 loss: 0.0016 lr: 0.02\n",
      "iteration: 395000 loss: 0.0017 lr: 0.02\n",
      "iteration: 396000 loss: 0.0017 lr: 0.02\n",
      "iteration: 397000 loss: 0.0017 lr: 0.02\n",
      "iteration: 398000 loss: 0.0017 lr: 0.02\n",
      "iteration: 399000 loss: 0.0016 lr: 0.02\n",
      "iteration: 400000 loss: 0.0017 lr: 0.02\n",
      "iteration: 401000 loss: 0.0017 lr: 0.02\n",
      "iteration: 402000 loss: 0.0016 lr: 0.02\n",
      "iteration: 403000 loss: 0.0016 lr: 0.02\n",
      "iteration: 404000 loss: 0.0017 lr: 0.02\n",
      "iteration: 405000 loss: 0.0017 lr: 0.02\n",
      "iteration: 406000 loss: 0.0016 lr: 0.02\n",
      "iteration: 407000 loss: 0.0016 lr: 0.02\n",
      "iteration: 408000 loss: 0.0016 lr: 0.02\n",
      "iteration: 409000 loss: 0.0017 lr: 0.02\n",
      "iteration: 410000 loss: 0.0016 lr: 0.02\n",
      "iteration: 411000 loss: 0.0016 lr: 0.02\n",
      "iteration: 412000 loss: 0.0017 lr: 0.02\n",
      "iteration: 413000 loss: 0.0017 lr: 0.02\n",
      "iteration: 414000 loss: 0.0017 lr: 0.02\n",
      "iteration: 415000 loss: 0.0017 lr: 0.02\n",
      "iteration: 416000 loss: 0.0017 lr: 0.02\n",
      "iteration: 417000 loss: 0.0017 lr: 0.02\n",
      "iteration: 418000 loss: 0.0016 lr: 0.02\n",
      "iteration: 419000 loss: 0.0016 lr: 0.02\n",
      "iteration: 420000 loss: 0.0017 lr: 0.02\n",
      "iteration: 421000 loss: 0.0016 lr: 0.02\n",
      "iteration: 422000 loss: 0.0016 lr: 0.02\n",
      "iteration: 423000 loss: 0.0017 lr: 0.02\n",
      "iteration: 424000 loss: 0.0016 lr: 0.02\n",
      "iteration: 425000 loss: 0.0016 lr: 0.02\n",
      "iteration: 426000 loss: 0.0017 lr: 0.02\n",
      "iteration: 427000 loss: 0.0016 lr: 0.02\n",
      "iteration: 428000 loss: 0.0017 lr: 0.02\n",
      "iteration: 429000 loss: 0.0017 lr: 0.02\n",
      "iteration: 430000 loss: 0.0016 lr: 0.02\n",
      "iteration: 431000 loss: 0.0015 lr: 0.002\n",
      "iteration: 432000 loss: 0.0015 lr: 0.002\n",
      "iteration: 433000 loss: 0.0015 lr: 0.002\n",
      "iteration: 434000 loss: 0.0015 lr: 0.002\n",
      "iteration: 435000 loss: 0.0015 lr: 0.002\n",
      "iteration: 436000 loss: 0.0015 lr: 0.002\n",
      "iteration: 437000 loss: 0.0015 lr: 0.002\n",
      "iteration: 438000 loss: 0.0014 lr: 0.002\n",
      "iteration: 439000 loss: 0.0015 lr: 0.002\n",
      "iteration: 440000 loss: 0.0014 lr: 0.002\n",
      "iteration: 441000 loss: 0.0014 lr: 0.002\n",
      "iteration: 442000 loss: 0.0014 lr: 0.002\n",
      "iteration: 443000 loss: 0.0015 lr: 0.002\n",
      "iteration: 444000 loss: 0.0014 lr: 0.002\n",
      "iteration: 445000 loss: 0.0014 lr: 0.002\n",
      "iteration: 446000 loss: 0.0014 lr: 0.002\n",
      "iteration: 447000 loss: 0.0015 lr: 0.002\n",
      "iteration: 448000 loss: 0.0014 lr: 0.002\n",
      "iteration: 449000 loss: 0.0014 lr: 0.002\n",
      "iteration: 450000 loss: 0.0014 lr: 0.002\n",
      "iteration: 451000 loss: 0.0015 lr: 0.002\n",
      "iteration: 452000 loss: 0.0014 lr: 0.002\n",
      "iteration: 453000 loss: 0.0014 lr: 0.002\n",
      "iteration: 454000 loss: 0.0014 lr: 0.002\n",
      "iteration: 455000 loss: 0.0014 lr: 0.002\n",
      "iteration: 456000 loss: 0.0014 lr: 0.002\n",
      "iteration: 457000 loss: 0.0014 lr: 0.002\n",
      "iteration: 458000 loss: 0.0014 lr: 0.002\n",
      "iteration: 459000 loss: 0.0014 lr: 0.002\n",
      "iteration: 460000 loss: 0.0014 lr: 0.002\n",
      "iteration: 461000 loss: 0.0014 lr: 0.002\n",
      "iteration: 462000 loss: 0.0014 lr: 0.002\n",
      "iteration: 463000 loss: 0.0014 lr: 0.002\n",
      "iteration: 464000 loss: 0.0014 lr: 0.002\n",
      "iteration: 465000 loss: 0.0015 lr: 0.002\n",
      "iteration: 466000 loss: 0.0014 lr: 0.002\n",
      "iteration: 467000 loss: 0.0014 lr: 0.002\n",
      "iteration: 468000 loss: 0.0014 lr: 0.002\n",
      "iteration: 469000 loss: 0.0014 lr: 0.002\n",
      "iteration: 470000 loss: 0.0014 lr: 0.002\n",
      "iteration: 471000 loss: 0.0014 lr: 0.002\n",
      "iteration: 472000 loss: 0.0014 lr: 0.002\n",
      "iteration: 473000 loss: 0.0014 lr: 0.002\n",
      "iteration: 474000 loss: 0.0014 lr: 0.002\n",
      "iteration: 475000 loss: 0.0014 lr: 0.002\n",
      "iteration: 476000 loss: 0.0014 lr: 0.002\n",
      "iteration: 477000 loss: 0.0014 lr: 0.002\n",
      "iteration: 478000 loss: 0.0014 lr: 0.002\n",
      "iteration: 479000 loss: 0.0014 lr: 0.002\n",
      "iteration: 480000 loss: 0.0014 lr: 0.002\n",
      "iteration: 481000 loss: 0.0014 lr: 0.002\n",
      "iteration: 482000 loss: 0.0014 lr: 0.002\n",
      "iteration: 483000 loss: 0.0014 lr: 0.002\n",
      "iteration: 484000 loss: 0.0014 lr: 0.002\n",
      "iteration: 485000 loss: 0.0014 lr: 0.002\n",
      "iteration: 486000 loss: 0.0014 lr: 0.002\n",
      "iteration: 487000 loss: 0.0014 lr: 0.002\n",
      "iteration: 488000 loss: 0.0014 lr: 0.002\n",
      "iteration: 489000 loss: 0.0014 lr: 0.002\n",
      "iteration: 490000 loss: 0.0014 lr: 0.002\n",
      "iteration: 491000 loss: 0.0014 lr: 0.002\n",
      "iteration: 492000 loss: 0.0014 lr: 0.002\n",
      "iteration: 493000 loss: 0.0014 lr: 0.002\n",
      "iteration: 494000 loss: 0.0014 lr: 0.002\n",
      "iteration: 495000 loss: 0.0014 lr: 0.002\n",
      "iteration: 496000 loss: 0.0014 lr: 0.002\n",
      "iteration: 497000 loss: 0.0014 lr: 0.002\n",
      "iteration: 498000 loss: 0.0014 lr: 0.002\n",
      "iteration: 499000 loss: 0.0014 lr: 0.002\n",
      "iteration: 500000 loss: 0.0014 lr: 0.002\n",
      "iteration: 501000 loss: 0.0014 lr: 0.002\n",
      "iteration: 502000 loss: 0.0014 lr: 0.002\n",
      "iteration: 503000 loss: 0.0014 lr: 0.002\n",
      "iteration: 504000 loss: 0.0014 lr: 0.002\n",
      "iteration: 505000 loss: 0.0014 lr: 0.002\n",
      "iteration: 506000 loss: 0.0014 lr: 0.002\n",
      "iteration: 507000 loss: 0.0014 lr: 0.002\n",
      "iteration: 508000 loss: 0.0014 lr: 0.002\n",
      "iteration: 509000 loss: 0.0014 lr: 0.002\n",
      "iteration: 510000 loss: 0.0014 lr: 0.002\n",
      "iteration: 511000 loss: 0.0014 lr: 0.002\n",
      "iteration: 512000 loss: 0.0014 lr: 0.002\n",
      "iteration: 513000 loss: 0.0014 lr: 0.002\n",
      "iteration: 514000 loss: 0.0014 lr: 0.002\n",
      "iteration: 515000 loss: 0.0014 lr: 0.002\n",
      "iteration: 516000 loss: 0.0014 lr: 0.002\n",
      "iteration: 517000 loss: 0.0014 lr: 0.002\n",
      "iteration: 518000 loss: 0.0014 lr: 0.002\n",
      "iteration: 519000 loss: 0.0014 lr: 0.002\n",
      "iteration: 520000 loss: 0.0014 lr: 0.002\n",
      "iteration: 521000 loss: 0.0014 lr: 0.002\n",
      "iteration: 522000 loss: 0.0014 lr: 0.002\n",
      "iteration: 523000 loss: 0.0014 lr: 0.002\n",
      "iteration: 524000 loss: 0.0014 lr: 0.002\n",
      "iteration: 525000 loss: 0.0014 lr: 0.002\n",
      "iteration: 526000 loss: 0.0014 lr: 0.002\n",
      "iteration: 527000 loss: 0.0014 lr: 0.002\n",
      "iteration: 528000 loss: 0.0014 lr: 0.002\n",
      "iteration: 529000 loss: 0.0014 lr: 0.002\n",
      "iteration: 530000 loss: 0.0014 lr: 0.002\n",
      "iteration: 531000 loss: 0.0014 lr: 0.002\n",
      "iteration: 532000 loss: 0.0014 lr: 0.002\n",
      "iteration: 533000 loss: 0.0014 lr: 0.002\n",
      "iteration: 534000 loss: 0.0014 lr: 0.002\n",
      "iteration: 535000 loss: 0.0014 lr: 0.002\n",
      "iteration: 536000 loss: 0.0014 lr: 0.002\n",
      "iteration: 537000 loss: 0.0014 lr: 0.002\n",
      "iteration: 538000 loss: 0.0014 lr: 0.002\n",
      "iteration: 539000 loss: 0.0014 lr: 0.002\n",
      "iteration: 540000 loss: 0.0014 lr: 0.002\n",
      "iteration: 541000 loss: 0.0014 lr: 0.002\n",
      "iteration: 542000 loss: 0.0014 lr: 0.002\n",
      "iteration: 543000 loss: 0.0014 lr: 0.002\n",
      "iteration: 544000 loss: 0.0014 lr: 0.002\n",
      "iteration: 545000 loss: 0.0014 lr: 0.002\n",
      "iteration: 546000 loss: 0.0014 lr: 0.002\n",
      "iteration: 547000 loss: 0.0014 lr: 0.002\n",
      "iteration: 548000 loss: 0.0014 lr: 0.002\n",
      "iteration: 549000 loss: 0.0014 lr: 0.002\n",
      "iteration: 550000 loss: 0.0014 lr: 0.002\n",
      "iteration: 551000 loss: 0.0014 lr: 0.002\n",
      "iteration: 552000 loss: 0.0014 lr: 0.002\n",
      "iteration: 553000 loss: 0.0014 lr: 0.002\n",
      "iteration: 554000 loss: 0.0014 lr: 0.002\n",
      "iteration: 555000 loss: 0.0014 lr: 0.002\n",
      "iteration: 556000 loss: 0.0014 lr: 0.002\n",
      "iteration: 557000 loss: 0.0014 lr: 0.002\n",
      "iteration: 558000 loss: 0.0014 lr: 0.002\n",
      "iteration: 559000 loss: 0.0014 lr: 0.002\n",
      "iteration: 560000 loss: 0.0014 lr: 0.002\n",
      "iteration: 561000 loss: 0.0014 lr: 0.002\n",
      "iteration: 562000 loss: 0.0014 lr: 0.002\n",
      "iteration: 563000 loss: 0.0014 lr: 0.002\n",
      "iteration: 564000 loss: 0.0014 lr: 0.002\n",
      "iteration: 565000 loss: 0.0014 lr: 0.002\n",
      "iteration: 566000 loss: 0.0014 lr: 0.002\n",
      "iteration: 567000 loss: 0.0014 lr: 0.002\n",
      "iteration: 568000 loss: 0.0014 lr: 0.002\n",
      "iteration: 569000 loss: 0.0014 lr: 0.002\n",
      "iteration: 570000 loss: 0.0014 lr: 0.002\n",
      "iteration: 571000 loss: 0.0014 lr: 0.002\n",
      "iteration: 572000 loss: 0.0014 lr: 0.002\n",
      "iteration: 573000 loss: 0.0014 lr: 0.002\n",
      "iteration: 574000 loss: 0.0014 lr: 0.002\n",
      "iteration: 575000 loss: 0.0014 lr: 0.002\n",
      "iteration: 576000 loss: 0.0014 lr: 0.002\n",
      "iteration: 577000 loss: 0.0014 lr: 0.002\n",
      "iteration: 578000 loss: 0.0014 lr: 0.002\n",
      "iteration: 579000 loss: 0.0014 lr: 0.002\n",
      "iteration: 580000 loss: 0.0014 lr: 0.002\n",
      "iteration: 581000 loss: 0.0014 lr: 0.002\n",
      "iteration: 582000 loss: 0.0014 lr: 0.002\n",
      "iteration: 583000 loss: 0.0014 lr: 0.002\n",
      "iteration: 584000 loss: 0.0014 lr: 0.002\n",
      "iteration: 585000 loss: 0.0014 lr: 0.002\n",
      "iteration: 586000 loss: 0.0014 lr: 0.002\n",
      "iteration: 587000 loss: 0.0013 lr: 0.002\n",
      "iteration: 588000 loss: 0.0014 lr: 0.002\n",
      "iteration: 589000 loss: 0.0014 lr: 0.002\n",
      "iteration: 590000 loss: 0.0014 lr: 0.002\n",
      "iteration: 591000 loss: 0.0014 lr: 0.002\n",
      "iteration: 592000 loss: 0.0013 lr: 0.002\n",
      "iteration: 593000 loss: 0.0014 lr: 0.002\n",
      "iteration: 594000 loss: 0.0014 lr: 0.002\n",
      "iteration: 595000 loss: 0.0014 lr: 0.002\n",
      "iteration: 596000 loss: 0.0014 lr: 0.002\n",
      "iteration: 597000 loss: 0.0014 lr: 0.002\n",
      "iteration: 598000 loss: 0.0014 lr: 0.002\n",
      "iteration: 599000 loss: 0.0014 lr: 0.002\n",
      "iteration: 600000 loss: 0.0014 lr: 0.002\n",
      "iteration: 601000 loss: 0.0014 lr: 0.002\n",
      "iteration: 602000 loss: 0.0014 lr: 0.002\n",
      "iteration: 603000 loss: 0.0014 lr: 0.002\n",
      "iteration: 604000 loss: 0.0014 lr: 0.002\n",
      "iteration: 605000 loss: 0.0014 lr: 0.002\n",
      "iteration: 606000 loss: 0.0013 lr: 0.002\n",
      "iteration: 607000 loss: 0.0014 lr: 0.002\n",
      "iteration: 608000 loss: 0.0014 lr: 0.002\n",
      "iteration: 609000 loss: 0.0014 lr: 0.002\n",
      "iteration: 610000 loss: 0.0014 lr: 0.002\n",
      "iteration: 611000 loss: 0.0014 lr: 0.002\n",
      "iteration: 612000 loss: 0.0014 lr: 0.002\n",
      "iteration: 613000 loss: 0.0014 lr: 0.002\n",
      "iteration: 614000 loss: 0.0014 lr: 0.002\n",
      "iteration: 615000 loss: 0.0014 lr: 0.002\n",
      "iteration: 616000 loss: 0.0014 lr: 0.002\n",
      "iteration: 617000 loss: 0.0014 lr: 0.002\n",
      "iteration: 618000 loss: 0.0014 lr: 0.002\n",
      "iteration: 619000 loss: 0.0014 lr: 0.002\n",
      "iteration: 620000 loss: 0.0014 lr: 0.002\n",
      "iteration: 621000 loss: 0.0014 lr: 0.002\n",
      "iteration: 622000 loss: 0.0014 lr: 0.002\n",
      "iteration: 623000 loss: 0.0014 lr: 0.002\n",
      "iteration: 624000 loss: 0.0014 lr: 0.002\n",
      "iteration: 625000 loss: 0.0014 lr: 0.002\n",
      "iteration: 626000 loss: 0.0014 lr: 0.002\n",
      "iteration: 627000 loss: 0.0014 lr: 0.002\n",
      "iteration: 628000 loss: 0.0014 lr: 0.002\n",
      "iteration: 629000 loss: 0.0014 lr: 0.002\n",
      "iteration: 630000 loss: 0.0014 lr: 0.002\n",
      "iteration: 631000 loss: 0.0014 lr: 0.002\n",
      "iteration: 632000 loss: 0.0014 lr: 0.002\n",
      "iteration: 633000 loss: 0.0014 lr: 0.002\n",
      "iteration: 634000 loss: 0.0014 lr: 0.002\n",
      "iteration: 635000 loss: 0.0014 lr: 0.002\n",
      "iteration: 636000 loss: 0.0014 lr: 0.002\n",
      "iteration: 637000 loss: 0.0014 lr: 0.002\n",
      "iteration: 638000 loss: 0.0014 lr: 0.002\n",
      "iteration: 639000 loss: 0.0014 lr: 0.002\n",
      "iteration: 640000 loss: 0.0014 lr: 0.002\n",
      "iteration: 641000 loss: 0.0014 lr: 0.002\n",
      "iteration: 642000 loss: 0.0014 lr: 0.002\n",
      "iteration: 643000 loss: 0.0014 lr: 0.002\n",
      "iteration: 644000 loss: 0.0014 lr: 0.002\n",
      "iteration: 645000 loss: 0.0014 lr: 0.002\n",
      "iteration: 646000 loss: 0.0014 lr: 0.002\n",
      "iteration: 647000 loss: 0.0014 lr: 0.002\n",
      "iteration: 648000 loss: 0.0015 lr: 0.002\n",
      "iteration: 649000 loss: 0.0014 lr: 0.002\n",
      "iteration: 650000 loss: 0.0014 lr: 0.002\n",
      "iteration: 651000 loss: 0.0014 lr: 0.002\n",
      "iteration: 652000 loss: 0.0014 lr: 0.002\n",
      "iteration: 653000 loss: 0.0014 lr: 0.002\n",
      "iteration: 654000 loss: 0.0014 lr: 0.002\n",
      "iteration: 655000 loss: 0.0014 lr: 0.002\n",
      "iteration: 656000 loss: 0.0013 lr: 0.002\n",
      "iteration: 657000 loss: 0.0014 lr: 0.002\n",
      "iteration: 658000 loss: 0.0013 lr: 0.002\n",
      "iteration: 659000 loss: 0.0014 lr: 0.002\n",
      "iteration: 660000 loss: 0.0014 lr: 0.002\n",
      "iteration: 661000 loss: 0.0014 lr: 0.002\n",
      "iteration: 662000 loss: 0.0014 lr: 0.002\n",
      "iteration: 663000 loss: 0.0014 lr: 0.002\n",
      "iteration: 664000 loss: 0.0014 lr: 0.002\n",
      "iteration: 665000 loss: 0.0014 lr: 0.002\n",
      "iteration: 666000 loss: 0.0014 lr: 0.002\n",
      "iteration: 667000 loss: 0.0014 lr: 0.002\n",
      "iteration: 668000 loss: 0.0014 lr: 0.002\n",
      "iteration: 669000 loss: 0.0014 lr: 0.002\n",
      "iteration: 670000 loss: 0.0014 lr: 0.002\n",
      "iteration: 671000 loss: 0.0014 lr: 0.002\n",
      "iteration: 672000 loss: 0.0014 lr: 0.002\n",
      "iteration: 673000 loss: 0.0014 lr: 0.002\n",
      "iteration: 674000 loss: 0.0014 lr: 0.002\n",
      "iteration: 675000 loss: 0.0014 lr: 0.002\n",
      "iteration: 676000 loss: 0.0014 lr: 0.002\n",
      "iteration: 677000 loss: 0.0014 lr: 0.002\n",
      "iteration: 678000 loss: 0.0014 lr: 0.002\n",
      "iteration: 679000 loss: 0.0014 lr: 0.002\n",
      "iteration: 680000 loss: 0.0014 lr: 0.002\n",
      "iteration: 681000 loss: 0.0014 lr: 0.002\n",
      "iteration: 682000 loss: 0.0014 lr: 0.002\n",
      "iteration: 683000 loss: 0.0014 lr: 0.002\n",
      "iteration: 684000 loss: 0.0014 lr: 0.002\n",
      "iteration: 685000 loss: 0.0014 lr: 0.002\n",
      "iteration: 686000 loss: 0.0014 lr: 0.002\n",
      "iteration: 687000 loss: 0.0014 lr: 0.002\n",
      "iteration: 688000 loss: 0.0014 lr: 0.002\n",
      "iteration: 689000 loss: 0.0014 lr: 0.002\n",
      "iteration: 690000 loss: 0.0014 lr: 0.002\n",
      "iteration: 691000 loss: 0.0014 lr: 0.002\n",
      "iteration: 692000 loss: 0.0014 lr: 0.002\n",
      "iteration: 693000 loss: 0.0014 lr: 0.002\n",
      "iteration: 694000 loss: 0.0014 lr: 0.002\n",
      "iteration: 695000 loss: 0.0014 lr: 0.002\n",
      "iteration: 696000 loss: 0.0014 lr: 0.002\n",
      "iteration: 697000 loss: 0.0014 lr: 0.002\n",
      "iteration: 698000 loss: 0.0014 lr: 0.002\n",
      "iteration: 699000 loss: 0.0014 lr: 0.002\n",
      "iteration: 700000 loss: 0.0014 lr: 0.002\n",
      "iteration: 701000 loss: 0.0014 lr: 0.002\n",
      "iteration: 702000 loss: 0.0014 lr: 0.002\n",
      "iteration: 703000 loss: 0.0014 lr: 0.002\n",
      "iteration: 704000 loss: 0.0014 lr: 0.002\n",
      "iteration: 705000 loss: 0.0014 lr: 0.002\n",
      "iteration: 706000 loss: 0.0014 lr: 0.002\n",
      "iteration: 707000 loss: 0.0014 lr: 0.002\n",
      "iteration: 708000 loss: 0.0014 lr: 0.002\n",
      "iteration: 709000 loss: 0.0014 lr: 0.002\n",
      "iteration: 710000 loss: 0.0014 lr: 0.002\n",
      "iteration: 711000 loss: 0.0014 lr: 0.002\n",
      "iteration: 712000 loss: 0.0014 lr: 0.002\n",
      "iteration: 713000 loss: 0.0014 lr: 0.002\n",
      "iteration: 714000 loss: 0.0014 lr: 0.002\n",
      "iteration: 715000 loss: 0.0014 lr: 0.002\n",
      "iteration: 716000 loss: 0.0014 lr: 0.002\n",
      "iteration: 717000 loss: 0.0014 lr: 0.002\n",
      "iteration: 718000 loss: 0.0014 lr: 0.002\n",
      "iteration: 719000 loss: 0.0014 lr: 0.002\n",
      "iteration: 720000 loss: 0.0014 lr: 0.002\n",
      "iteration: 721000 loss: 0.0014 lr: 0.002\n",
      "iteration: 722000 loss: 0.0014 lr: 0.002\n",
      "iteration: 723000 loss: 0.0014 lr: 0.002\n",
      "iteration: 724000 loss: 0.0014 lr: 0.002\n",
      "iteration: 725000 loss: 0.0014 lr: 0.002\n",
      "iteration: 726000 loss: 0.0014 lr: 0.002\n",
      "iteration: 727000 loss: 0.0014 lr: 0.002\n",
      "iteration: 728000 loss: 0.0014 lr: 0.002\n",
      "iteration: 729000 loss: 0.0014 lr: 0.002\n",
      "iteration: 730000 loss: 0.0014 lr: 0.002\n",
      "iteration: 731000 loss: 0.0014 lr: 0.001\n",
      "iteration: 732000 loss: 0.0014 lr: 0.001\n",
      "iteration: 733000 loss: 0.0014 lr: 0.001\n",
      "iteration: 734000 loss: 0.0014 lr: 0.001\n",
      "iteration: 735000 loss: 0.0014 lr: 0.001\n",
      "iteration: 736000 loss: 0.0013 lr: 0.001\n",
      "iteration: 737000 loss: 0.0014 lr: 0.001\n",
      "iteration: 738000 loss: 0.0014 lr: 0.001\n",
      "iteration: 739000 loss: 0.0014 lr: 0.001\n",
      "iteration: 740000 loss: 0.0014 lr: 0.001\n",
      "iteration: 741000 loss: 0.0014 lr: 0.001\n",
      "iteration: 742000 loss: 0.0014 lr: 0.001\n",
      "iteration: 743000 loss: 0.0014 lr: 0.001\n",
      "iteration: 744000 loss: 0.0014 lr: 0.001\n",
      "iteration: 745000 loss: 0.0014 lr: 0.001\n",
      "iteration: 746000 loss: 0.0013 lr: 0.001\n",
      "iteration: 747000 loss: 0.0013 lr: 0.001\n",
      "iteration: 748000 loss: 0.0014 lr: 0.001\n",
      "iteration: 749000 loss: 0.0013 lr: 0.001\n",
      "iteration: 750000 loss: 0.0014 lr: 0.001\n",
      "iteration: 751000 loss: 0.0014 lr: 0.001\n",
      "iteration: 752000 loss: 0.0014 lr: 0.001\n",
      "iteration: 753000 loss: 0.0013 lr: 0.001\n",
      "iteration: 754000 loss: 0.0013 lr: 0.001\n",
      "iteration: 755000 loss: 0.0014 lr: 0.001\n",
      "iteration: 756000 loss: 0.0014 lr: 0.001\n",
      "iteration: 757000 loss: 0.0014 lr: 0.001\n",
      "iteration: 758000 loss: 0.0014 lr: 0.001\n",
      "iteration: 759000 loss: 0.0014 lr: 0.001\n",
      "iteration: 760000 loss: 0.0014 lr: 0.001\n",
      "iteration: 761000 loss: 0.0014 lr: 0.001\n",
      "iteration: 762000 loss: 0.0013 lr: 0.001\n",
      "iteration: 763000 loss: 0.0013 lr: 0.001\n",
      "iteration: 764000 loss: 0.0013 lr: 0.001\n",
      "iteration: 765000 loss: 0.0014 lr: 0.001\n",
      "iteration: 766000 loss: 0.0014 lr: 0.001\n",
      "iteration: 767000 loss: 0.0014 lr: 0.001\n",
      "iteration: 768000 loss: 0.0013 lr: 0.001\n",
      "iteration: 769000 loss: 0.0013 lr: 0.001\n",
      "iteration: 770000 loss: 0.0014 lr: 0.001\n",
      "iteration: 771000 loss: 0.0014 lr: 0.001\n",
      "iteration: 772000 loss: 0.0014 lr: 0.001\n",
      "iteration: 773000 loss: 0.0013 lr: 0.001\n",
      "iteration: 774000 loss: 0.0013 lr: 0.001\n",
      "iteration: 775000 loss: 0.0014 lr: 0.001\n",
      "iteration: 776000 loss: 0.0013 lr: 0.001\n",
      "iteration: 777000 loss: 0.0014 lr: 0.001\n",
      "iteration: 778000 loss: 0.0014 lr: 0.001\n",
      "iteration: 779000 loss: 0.0014 lr: 0.001\n",
      "iteration: 780000 loss: 0.0014 lr: 0.001\n",
      "iteration: 781000 loss: 0.0014 lr: 0.001\n",
      "iteration: 782000 loss: 0.0014 lr: 0.001\n",
      "iteration: 783000 loss: 0.0014 lr: 0.001\n",
      "iteration: 784000 loss: 0.0014 lr: 0.001\n",
      "iteration: 785000 loss: 0.0014 lr: 0.001\n",
      "iteration: 786000 loss: 0.0014 lr: 0.001\n",
      "iteration: 787000 loss: 0.0013 lr: 0.001\n",
      "iteration: 788000 loss: 0.0014 lr: 0.001\n",
      "iteration: 789000 loss: 0.0014 lr: 0.001\n",
      "iteration: 790000 loss: 0.0014 lr: 0.001\n",
      "iteration: 791000 loss: 0.0014 lr: 0.001\n",
      "iteration: 792000 loss: 0.0013 lr: 0.001\n",
      "iteration: 793000 loss: 0.0014 lr: 0.001\n",
      "iteration: 794000 loss: 0.0013 lr: 0.001\n",
      "iteration: 795000 loss: 0.0014 lr: 0.001\n",
      "iteration: 796000 loss: 0.0014 lr: 0.001\n",
      "iteration: 797000 loss: 0.0014 lr: 0.001\n",
      "iteration: 798000 loss: 0.0013 lr: 0.001\n",
      "iteration: 799000 loss: 0.0014 lr: 0.001\n",
      "iteration: 800000 loss: 0.0013 lr: 0.001\n",
      "iteration: 801000 loss: 0.0014 lr: 0.001\n",
      "iteration: 802000 loss: 0.0013 lr: 0.001\n",
      "iteration: 803000 loss: 0.0013 lr: 0.001\n",
      "iteration: 804000 loss: 0.0014 lr: 0.001\n",
      "iteration: 805000 loss: 0.0013 lr: 0.001\n",
      "iteration: 806000 loss: 0.0013 lr: 0.001\n",
      "iteration: 807000 loss: 0.0014 lr: 0.001\n",
      "iteration: 808000 loss: 0.0013 lr: 0.001\n",
      "iteration: 809000 loss: 0.0014 lr: 0.001\n",
      "iteration: 810000 loss: 0.0014 lr: 0.001\n",
      "iteration: 811000 loss: 0.0013 lr: 0.001\n",
      "iteration: 812000 loss: 0.0014 lr: 0.001\n",
      "iteration: 813000 loss: 0.0014 lr: 0.001\n",
      "iteration: 814000 loss: 0.0014 lr: 0.001\n",
      "iteration: 815000 loss: 0.0014 lr: 0.001\n",
      "iteration: 816000 loss: 0.0014 lr: 0.001\n",
      "iteration: 817000 loss: 0.0013 lr: 0.001\n",
      "iteration: 818000 loss: 0.0014 lr: 0.001\n",
      "iteration: 819000 loss: 0.0014 lr: 0.001\n",
      "iteration: 820000 loss: 0.0013 lr: 0.001\n",
      "iteration: 821000 loss: 0.0013 lr: 0.001\n",
      "iteration: 822000 loss: 0.0014 lr: 0.001\n",
      "iteration: 823000 loss: 0.0014 lr: 0.001\n",
      "iteration: 824000 loss: 0.0014 lr: 0.001\n",
      "iteration: 825000 loss: 0.0014 lr: 0.001\n",
      "iteration: 826000 loss: 0.0014 lr: 0.001\n",
      "iteration: 827000 loss: 0.0013 lr: 0.001\n",
      "iteration: 828000 loss: 0.0013 lr: 0.001\n",
      "iteration: 829000 loss: 0.0014 lr: 0.001\n",
      "iteration: 830000 loss: 0.0013 lr: 0.001\n",
      "iteration: 831000 loss: 0.0013 lr: 0.001\n",
      "iteration: 832000 loss: 0.0013 lr: 0.001\n",
      "iteration: 833000 loss: 0.0013 lr: 0.001\n",
      "iteration: 834000 loss: 0.0013 lr: 0.001\n",
      "iteration: 835000 loss: 0.0014 lr: 0.001\n",
      "iteration: 836000 loss: 0.0013 lr: 0.001\n",
      "iteration: 837000 loss: 0.0014 lr: 0.001\n",
      "iteration: 838000 loss: 0.0014 lr: 0.001\n",
      "iteration: 839000 loss: 0.0014 lr: 0.001\n",
      "iteration: 840000 loss: 0.0014 lr: 0.001\n",
      "iteration: 841000 loss: 0.0014 lr: 0.001\n",
      "iteration: 842000 loss: 0.0013 lr: 0.001\n",
      "iteration: 843000 loss: 0.0014 lr: 0.001\n",
      "iteration: 844000 loss: 0.0014 lr: 0.001\n",
      "iteration: 845000 loss: 0.0013 lr: 0.001\n",
      "iteration: 846000 loss: 0.0014 lr: 0.001\n",
      "iteration: 847000 loss: 0.0013 lr: 0.001\n",
      "iteration: 848000 loss: 0.0014 lr: 0.001\n",
      "iteration: 849000 loss: 0.0014 lr: 0.001\n",
      "iteration: 850000 loss: 0.0013 lr: 0.001\n",
      "iteration: 851000 loss: 0.0014 lr: 0.001\n",
      "iteration: 852000 loss: 0.0013 lr: 0.001\n",
      "iteration: 853000 loss: 0.0014 lr: 0.001\n",
      "iteration: 854000 loss: 0.0014 lr: 0.001\n",
      "iteration: 855000 loss: 0.0014 lr: 0.001\n",
      "iteration: 856000 loss: 0.0014 lr: 0.001\n",
      "iteration: 857000 loss: 0.0013 lr: 0.001\n",
      "iteration: 858000 loss: 0.0013 lr: 0.001\n",
      "iteration: 859000 loss: 0.0013 lr: 0.001\n",
      "iteration: 860000 loss: 0.0014 lr: 0.001\n",
      "iteration: 861000 loss: 0.0013 lr: 0.001\n",
      "iteration: 862000 loss: 0.0013 lr: 0.001\n",
      "iteration: 863000 loss: 0.0013 lr: 0.001\n",
      "iteration: 864000 loss: 0.0014 lr: 0.001\n",
      "iteration: 865000 loss: 0.0013 lr: 0.001\n",
      "iteration: 866000 loss: 0.0014 lr: 0.001\n",
      "iteration: 867000 loss: 0.0013 lr: 0.001\n",
      "iteration: 868000 loss: 0.0014 lr: 0.001\n",
      "iteration: 869000 loss: 0.0013 lr: 0.001\n",
      "iteration: 870000 loss: 0.0013 lr: 0.001\n",
      "iteration: 871000 loss: 0.0014 lr: 0.001\n",
      "iteration: 872000 loss: 0.0014 lr: 0.001\n",
      "iteration: 873000 loss: 0.0013 lr: 0.001\n",
      "iteration: 874000 loss: 0.0013 lr: 0.001\n",
      "iteration: 875000 loss: 0.0014 lr: 0.001\n",
      "iteration: 876000 loss: 0.0014 lr: 0.001\n",
      "iteration: 877000 loss: 0.0014 lr: 0.001\n",
      "iteration: 878000 loss: 0.0013 lr: 0.001\n",
      "iteration: 879000 loss: 0.0014 lr: 0.001\n",
      "iteration: 880000 loss: 0.0014 lr: 0.001\n",
      "iteration: 881000 loss: 0.0013 lr: 0.001\n",
      "iteration: 882000 loss: 0.0014 lr: 0.001\n",
      "iteration: 883000 loss: 0.0014 lr: 0.001\n",
      "iteration: 884000 loss: 0.0013 lr: 0.001\n",
      "iteration: 885000 loss: 0.0013 lr: 0.001\n",
      "iteration: 886000 loss: 0.0014 lr: 0.001\n",
      "iteration: 887000 loss: 0.0013 lr: 0.001\n",
      "iteration: 888000 loss: 0.0014 lr: 0.001\n",
      "iteration: 889000 loss: 0.0014 lr: 0.001\n",
      "iteration: 890000 loss: 0.0013 lr: 0.001\n",
      "iteration: 891000 loss: 0.0013 lr: 0.001\n",
      "iteration: 892000 loss: 0.0013 lr: 0.001\n",
      "iteration: 893000 loss: 0.0014 lr: 0.001\n",
      "iteration: 894000 loss: 0.0013 lr: 0.001\n",
      "iteration: 895000 loss: 0.0013 lr: 0.001\n",
      "iteration: 896000 loss: 0.0014 lr: 0.001\n",
      "iteration: 897000 loss: 0.0013 lr: 0.001\n",
      "iteration: 898000 loss: 0.0014 lr: 0.001\n",
      "iteration: 899000 loss: 0.0013 lr: 0.001\n",
      "iteration: 900000 loss: 0.0014 lr: 0.001\n",
      "iteration: 901000 loss: 0.0013 lr: 0.001\n",
      "iteration: 902000 loss: 0.0014 lr: 0.001\n",
      "iteration: 903000 loss: 0.0014 lr: 0.001\n",
      "iteration: 904000 loss: 0.0014 lr: 0.001\n",
      "iteration: 905000 loss: 0.0014 lr: 0.001\n",
      "iteration: 906000 loss: 0.0013 lr: 0.001\n",
      "iteration: 907000 loss: 0.0014 lr: 0.001\n",
      "iteration: 908000 loss: 0.0013 lr: 0.001\n",
      "iteration: 909000 loss: 0.0013 lr: 0.001\n",
      "iteration: 910000 loss: 0.0014 lr: 0.001\n",
      "iteration: 911000 loss: 0.0013 lr: 0.001\n",
      "iteration: 912000 loss: 0.0013 lr: 0.001\n",
      "iteration: 913000 loss: 0.0014 lr: 0.001\n",
      "iteration: 914000 loss: 0.0014 lr: 0.001\n",
      "iteration: 915000 loss: 0.0013 lr: 0.001\n",
      "iteration: 916000 loss: 0.0014 lr: 0.001\n",
      "iteration: 917000 loss: 0.0013 lr: 0.001\n",
      "iteration: 918000 loss: 0.0013 lr: 0.001\n",
      "iteration: 919000 loss: 0.0013 lr: 0.001\n",
      "iteration: 920000 loss: 0.0013 lr: 0.001\n",
      "iteration: 921000 loss: 0.0014 lr: 0.001\n",
      "iteration: 922000 loss: 0.0013 lr: 0.001\n",
      "iteration: 923000 loss: 0.0013 lr: 0.001\n",
      "iteration: 924000 loss: 0.0013 lr: 0.001\n",
      "iteration: 925000 loss: 0.0014 lr: 0.001\n",
      "iteration: 926000 loss: 0.0013 lr: 0.001\n",
      "iteration: 927000 loss: 0.0013 lr: 0.001\n",
      "iteration: 928000 loss: 0.0013 lr: 0.001\n",
      "iteration: 929000 loss: 0.0013 lr: 0.001\n",
      "iteration: 930000 loss: 0.0014 lr: 0.001\n",
      "iteration: 931000 loss: 0.0013 lr: 0.001\n",
      "iteration: 932000 loss: 0.0013 lr: 0.001\n",
      "iteration: 933000 loss: 0.0013 lr: 0.001\n",
      "iteration: 934000 loss: 0.0013 lr: 0.001\n",
      "iteration: 935000 loss: 0.0013 lr: 0.001\n",
      "iteration: 936000 loss: 0.0013 lr: 0.001\n",
      "iteration: 937000 loss: 0.0013 lr: 0.001\n",
      "iteration: 938000 loss: 0.0013 lr: 0.001\n",
      "iteration: 939000 loss: 0.0013 lr: 0.001\n",
      "iteration: 940000 loss: 0.0013 lr: 0.001\n",
      "iteration: 941000 loss: 0.0014 lr: 0.001\n",
      "iteration: 942000 loss: 0.0013 lr: 0.001\n",
      "iteration: 943000 loss: 0.0013 lr: 0.001\n",
      "iteration: 944000 loss: 0.0014 lr: 0.001\n",
      "iteration: 945000 loss: 0.0013 lr: 0.001\n",
      "iteration: 946000 loss: 0.0013 lr: 0.001\n",
      "iteration: 947000 loss: 0.0014 lr: 0.001\n",
      "iteration: 948000 loss: 0.0014 lr: 0.001\n",
      "iteration: 949000 loss: 0.0013 lr: 0.001\n",
      "iteration: 950000 loss: 0.0013 lr: 0.001\n",
      "iteration: 951000 loss: 0.0013 lr: 0.001\n",
      "iteration: 952000 loss: 0.0014 lr: 0.001\n",
      "iteration: 953000 loss: 0.0013 lr: 0.001\n",
      "iteration: 954000 loss: 0.0013 lr: 0.001\n",
      "iteration: 955000 loss: 0.0013 lr: 0.001\n",
      "iteration: 956000 loss: 0.0013 lr: 0.001\n",
      "iteration: 957000 loss: 0.0013 lr: 0.001\n",
      "iteration: 958000 loss: 0.0014 lr: 0.001\n",
      "iteration: 959000 loss: 0.0014 lr: 0.001\n",
      "iteration: 960000 loss: 0.0013 lr: 0.001\n",
      "iteration: 961000 loss: 0.0014 lr: 0.001\n",
      "iteration: 962000 loss: 0.0013 lr: 0.001\n",
      "iteration: 963000 loss: 0.0013 lr: 0.001\n",
      "iteration: 964000 loss: 0.0014 lr: 0.001\n",
      "iteration: 965000 loss: 0.0013 lr: 0.001\n",
      "iteration: 966000 loss: 0.0014 lr: 0.001\n",
      "iteration: 967000 loss: 0.0013 lr: 0.001\n",
      "iteration: 968000 loss: 0.0013 lr: 0.001\n",
      "iteration: 969000 loss: 0.0013 lr: 0.001\n",
      "iteration: 970000 loss: 0.0013 lr: 0.001\n",
      "iteration: 971000 loss: 0.0013 lr: 0.001\n",
      "iteration: 972000 loss: 0.0014 lr: 0.001\n",
      "iteration: 973000 loss: 0.0013 lr: 0.001\n",
      "iteration: 974000 loss: 0.0013 lr: 0.001\n",
      "iteration: 975000 loss: 0.0014 lr: 0.001\n",
      "iteration: 976000 loss: 0.0013 lr: 0.001\n",
      "iteration: 977000 loss: 0.0013 lr: 0.001\n",
      "iteration: 978000 loss: 0.0013 lr: 0.001\n",
      "iteration: 979000 loss: 0.0013 lr: 0.001\n",
      "iteration: 980000 loss: 0.0013 lr: 0.001\n",
      "iteration: 981000 loss: 0.0013 lr: 0.001\n",
      "iteration: 982000 loss: 0.0013 lr: 0.001\n",
      "iteration: 983000 loss: 0.0014 lr: 0.001\n",
      "iteration: 984000 loss: 0.0013 lr: 0.001\n",
      "iteration: 985000 loss: 0.0013 lr: 0.001\n",
      "iteration: 986000 loss: 0.0013 lr: 0.001\n",
      "iteration: 987000 loss: 0.0013 lr: 0.001\n",
      "iteration: 988000 loss: 0.0013 lr: 0.001\n",
      "iteration: 989000 loss: 0.0013 lr: 0.001\n",
      "iteration: 990000 loss: 0.0013 lr: 0.001\n",
      "iteration: 991000 loss: 0.0013 lr: 0.001\n",
      "iteration: 992000 loss: 0.0013 lr: 0.001\n",
      "iteration: 993000 loss: 0.0013 lr: 0.001\n",
      "iteration: 994000 loss: 0.0013 lr: 0.001\n",
      "iteration: 995000 loss: 0.0013 lr: 0.001\n",
      "iteration: 996000 loss: 0.0013 lr: 0.001\n",
      "iteration: 997000 loss: 0.0013 lr: 0.001\n",
      "iteration: 998000 loss: 0.0014 lr: 0.001\n",
      "iteration: 999000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1000000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1001000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1002000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1003000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1004000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1005000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1006000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1007000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1008000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1009000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1010000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1011000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1012000 loss: 0.0014 lr: 0.001\n",
      "iteration: 1013000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1014000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1015000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1016000 loss: 0.0014 lr: 0.001\n",
      "iteration: 1017000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1018000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1019000 loss: 0.0014 lr: 0.001\n",
      "iteration: 1020000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1021000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1022000 loss: 0.0014 lr: 0.001\n",
      "iteration: 1023000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1024000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1025000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1026000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1027000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1028000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1029000 loss: 0.0013 lr: 0.001\n",
      "iteration: 1030000 loss: 0.0013 lr: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1075, in _run\n",
      "    raise RuntimeError('Attempted to use a closed Session.')\n",
      "RuntimeError: Attempted to use a closed Session.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlc.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.launch_dlc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
