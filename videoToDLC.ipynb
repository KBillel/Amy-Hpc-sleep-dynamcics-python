{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global x,y,pause\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.imshow(frame)\n",
    "    try:\n",
    "        x\n",
    "    except:\n",
    "        x = [0,0]\n",
    "    try:\n",
    "        y\n",
    "    except:\n",
    "        y = [0,0]\n",
    "    \n",
    "    if str(event.button) == \"MouseButton.LEFT\":\n",
    "        x[0], y[0] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.RIGHT\":\n",
    "        x[1], y[1] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.MIDDLE\":\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "        pause = False\n",
    "        \n",
    "    for i,j in zip(x,y):\n",
    "        plt.axvline(i)\n",
    "        plt.axhline(j)\n",
    "        plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/DeepLabCut_Tutorial_Temps/MonExperience/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_152809\\\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_103618\\\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_143126\\\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24-20210129_210129_163341\\\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_113321\\\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_152259\\\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4') and not file.endswith('labeled.mp4'): videos.append(os.path.join(subdirs,file))\n",
    "# config_path = 'E:\\classical_fear_conditionning\\classical_fear_conditionning-BM-2020-11-20\\config.yaml'\n",
    "videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([523.1363636363637, 825.1277056277058],\n",
       "  [202.8593073593072, 479.91558441558425]),\n",
       " ([464.9545454545455, 1027.3787878787882],\n",
       "  [233.33549783549768, 560.2619047619046]),\n",
       " ([381.8376623376623, 1052.3138528138531],\n",
       "  [122.51298701298674, 485.4567099567098]),\n",
       " ([398.461038961039, 947.0324675324678],\n",
       "  [183.46536796536782, 502.08008658008646]),\n",
       " ([376.29653679653677, 960.8852813852816],\n",
       "  [80.95454545454527, 574.1147186147185]),\n",
       " ([453.8722943722944, 980.2792207792211],\n",
       "  [158.5303030303029, 515.9329004329003])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop = []\n",
    "for v in videos:\n",
    "    try:\n",
    "        del x,y\n",
    "    except:\n",
    "        pass\n",
    "    cap = cv2.VideoCapture(v)\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    pause = True\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.imshow(frame)\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "    while pause:\n",
    "        plt.pause(0.1)\n",
    "    plt.close('all')\n",
    "    crop.append((x,y))\n",
    "    \n",
    "crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Videos : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [525, 870, 187, 510]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19667 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_152809\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_152809  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_152809\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4\n",
      "Duration of video [s]:  655.57 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19667  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 525 x2 = 870 y1 = 187 y2 = 510. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19796it [05:20, 61.70it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_152809...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_152809\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [475, 990, 234, 521]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19098 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_103618\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_103618  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_103618\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4\n",
      "Duration of video [s]:  636.6 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19098  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 475 x2 = 990 y1 = 234 y2 = 521. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19190it [05:34, 57.35it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_103618...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_103618\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [464, 1012, 201, 493]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19779 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_143126\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_143126  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_143126\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4\n",
      "Duration of video [s]:  659.3 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19779  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 464 x2 = 1012 y1 = 201 y2 = 493. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19897it [05:46, 57.45it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_143126...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_143126\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [519, 862, 165, 468]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19336 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24-20210129_210129_163341  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4\n",
      "Duration of video [s]:  644.53 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19336  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 519 x2 = 862 y1 = 165 y2 = 468. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19493it [04:56, 65.84it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24-20210129_210129_163341...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [475, 981, 209, 515]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19202 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_113321  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4\n",
      "Duration of video [s]:  640.07 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19202  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 475 x2 = 981 y1 = 209 y2 = 515. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19392it [05:36, 57.71it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_113321...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [478, 987, 218, 507]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_152259  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4\n",
      "Duration of video [s]:  638.63 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19159  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 478 x2 = 987 y1 = 218 y2 = 507. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19291it [05:29, 58.49it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_152259...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.analyze_videos(config_path,v,cropping=c,save_as_csv=True)\n",
    "    dlc.filterpredictions(config_path,v,save_as_csv = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create labeled Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select if you want to user filtered positions or not\n",
    "filt = False\n",
    "for v in videos:\n",
    "    dlc.create_labeled_video(config_path,v,filtered=filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Crop metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_152809\\\\Basler_acA1300-200uc__23039139__20210128_152809881DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_103618\\\\Basler_acA1300-200uc__23039139__20210128_103619873DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_143126\\\\Basler_acA1300-200uc__23039139__20210128_143130383DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24-20210129_210129_163341\\\\Basler_acA1300-200uc__23039139__20210129_163346459DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_113321\\\\Basler_acA1300-200uc__23039139__20210129_113328761DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_152259\\\\Basler_acA1300-200uc__23039139__20210129_152304254DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pickle'): metadata.append(os.path.join(subdirs,file))\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract outliers frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525 870 187 510\n",
      "Method  jump  found  3216  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20210128_152809881  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  655.5666666666667 , recorded @  30.0 fps!\n",
      "Overall # of frames:  19667 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 655.57  seconds.\n",
      "Extracting and downsampling... 3216  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3216it [01:10, 45.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [4823, 178, 19584, 645, 14415, 4157, 249, 1182, 669, 19655, 663, 594, 1593, 10447, 474, 10949, 19540, 8604, 19572, 13861]\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20210128_152809881.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "475 990 234 521\n",
      "Method  jump  found  2498  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "464 1012 201 493\n",
      "Method  jump  found  1005  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "519 862 165 468\n",
      "Method  jump  found  3275  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "475 981 209 515\n",
      "Method  jump  found  2903  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "478 987 218 507\n",
      "Method  jump  found  3260  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n"
     ]
    }
   ],
   "source": [
    "numframes2pick = 20\n",
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    print(x1,x2,y1,y2)\n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    \n",
    "    cfg['numframes2pick'] = numframes2pick\n",
    "    cfg['cropping'] = True\n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    \n",
    "    dlc.extract_outlier_frames(config_path,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                           | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Billel.\n",
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210128_152809881_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:04<00:00, 10.99it/s]\n",
      "  0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210128_103619873_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 11.48it/s]\n",
      "  0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210128_143130383_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.99it/s]\n",
      "  0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210129_113328761_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 11.61it/s]\n",
      "  0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210129_152304254_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210129_163346459_labeled  already exists!\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 1.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([42, 47, 30, 14, 29, 21, 33, 37,  3, 17, 18, 44, 35, 50, 12, 49, 52,\n",
       "           4,  9, 43, 45,  7, 22, 13, 15, 19, 32, 41,  0,  2, 51, 27, 11, 38,\n",
       "          16, 40, 39, 20, 25, 24, 34,  5, 28, 36,  1,  6, 31, 26, 10, 48, 23]),\n",
       "   array([ 8, 46, 53])))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'left_ear',\n",
      "                      'right_ear',\n",
      "                      'base_tail',\n",
      "                      'end_tail'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\fear_tuto_dlc_Billel95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Billel.Khouader\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\Documentation_data-fear_tuto_dlc_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut_Tutorial_Temps\\\\fear_tuto_dlc-Billel-2021-02-15\\\\dlc-models\\\\iteration-1\\\\fear_tuto_dlcFeb15-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\DeepLabCut_Tutorial_Temps\\\\fear_tuto_dlc-Billel-2021-02-15\\\\dlc-models\\\\iteration-1\\\\fear_tuto_dlcFeb15-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4]], 'all_joints_names': ['snout', 'left_ear', 'right_ear', 'base_tail', 'end_tail'], 'alpha_r': 0.02, 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\fear_tuto_dlc_Billel95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Billel.Khouader\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\Documentation_data-fear_tuto_dlc_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 5, 'pos_dist_thresh': 17, 'project_path': 'D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0394 lr: 0.005\n",
      "iteration: 2000 loss: 0.0252 lr: 0.005\n",
      "iteration: 3000 loss: 0.0204 lr: 0.005\n",
      "iteration: 4000 loss: 0.0173 lr: 0.005\n",
      "iteration: 5000 loss: 0.0154 lr: 0.005\n",
      "iteration: 6000 loss: 0.0138 lr: 0.005\n",
      "iteration: 7000 loss: 0.0125 lr: 0.005\n",
      "iteration: 8000 loss: 0.0118 lr: 0.005\n",
      "iteration: 9000 loss: 0.0113 lr: 0.005\n",
      "iteration: 10000 loss: 0.0108 lr: 0.005\n",
      "iteration: 11000 loss: 0.0149 lr: 0.02\n",
      "iteration: 12000 loss: 0.0128 lr: 0.02\n",
      "iteration: 13000 loss: 0.0113 lr: 0.02\n",
      "iteration: 14000 loss: 0.0110 lr: 0.02\n",
      "iteration: 15000 loss: 0.0099 lr: 0.02\n",
      "iteration: 16000 loss: 0.0092 lr: 0.02\n",
      "iteration: 17000 loss: 0.0092 lr: 0.02\n",
      "iteration: 18000 loss: 0.0087 lr: 0.02\n",
      "iteration: 19000 loss: 0.0088 lr: 0.02\n",
      "iteration: 20000 loss: 0.0083 lr: 0.02\n",
      "iteration: 21000 loss: 0.0081 lr: 0.02\n",
      "iteration: 22000 loss: 0.0078 lr: 0.02\n",
      "iteration: 23000 loss: 0.0076 lr: 0.02\n",
      "iteration: 24000 loss: 0.0076 lr: 0.02\n",
      "iteration: 25000 loss: 0.0074 lr: 0.02\n",
      "iteration: 26000 loss: 0.0072 lr: 0.02\n",
      "iteration: 27000 loss: 0.0071 lr: 0.02\n",
      "iteration: 28000 loss: 0.0071 lr: 0.02\n",
      "iteration: 29000 loss: 0.0070 lr: 0.02\n",
      "iteration: 30000 loss: 0.0069 lr: 0.02\n",
      "iteration: 31000 loss: 0.0066 lr: 0.02\n",
      "iteration: 32000 loss: 0.0066 lr: 0.02\n",
      "iteration: 33000 loss: 0.0066 lr: 0.02\n",
      "iteration: 34000 loss: 0.0068 lr: 0.02\n",
      "iteration: 35000 loss: 0.0063 lr: 0.02\n",
      "iteration: 36000 loss: 0.0063 lr: 0.02\n",
      "iteration: 37000 loss: 0.0062 lr: 0.02\n",
      "iteration: 38000 loss: 0.0063 lr: 0.02\n",
      "iteration: 39000 loss: 0.0063 lr: 0.02\n",
      "iteration: 40000 loss: 0.0062 lr: 0.02\n",
      "iteration: 41000 loss: 0.0061 lr: 0.02\n",
      "iteration: 42000 loss: 0.0059 lr: 0.02\n",
      "iteration: 43000 loss: 0.0059 lr: 0.02\n",
      "iteration: 44000 loss: 0.0060 lr: 0.02\n",
      "iteration: 45000 loss: 0.0057 lr: 0.02\n",
      "iteration: 46000 loss: 0.0057 lr: 0.02\n",
      "iteration: 47000 loss: 0.0057 lr: 0.02\n",
      "iteration: 48000 loss: 0.0056 lr: 0.02\n",
      "iteration: 49000 loss: 0.0057 lr: 0.02\n",
      "iteration: 50000 loss: 0.0057 lr: 0.02\n",
      "iteration: 51000 loss: 0.0057 lr: 0.02\n",
      "iteration: 52000 loss: 0.0055 lr: 0.02\n",
      "iteration: 53000 loss: 0.0055 lr: 0.02\n",
      "iteration: 54000 loss: 0.0053 lr: 0.02\n",
      "iteration: 55000 loss: 0.0053 lr: 0.02\n",
      "iteration: 56000 loss: 0.0052 lr: 0.02\n",
      "iteration: 57000 loss: 0.0053 lr: 0.02\n",
      "iteration: 58000 loss: 0.0055 lr: 0.02\n",
      "iteration: 59000 loss: 0.0053 lr: 0.02\n",
      "iteration: 60000 loss: 0.0053 lr: 0.02\n",
      "iteration: 61000 loss: 0.0052 lr: 0.02\n",
      "iteration: 62000 loss: 0.0052 lr: 0.02\n",
      "iteration: 63000 loss: 0.0051 lr: 0.02\n",
      "iteration: 64000 loss: 0.0051 lr: 0.02\n",
      "iteration: 65000 loss: 0.0051 lr: 0.02\n",
      "iteration: 66000 loss: 0.0051 lr: 0.02\n",
      "iteration: 67000 loss: 0.0050 lr: 0.02\n",
      "iteration: 68000 loss: 0.0050 lr: 0.02\n",
      "iteration: 69000 loss: 0.0050 lr: 0.02\n",
      "iteration: 70000 loss: 0.0048 lr: 0.02\n",
      "iteration: 71000 loss: 0.0051 lr: 0.02\n",
      "iteration: 72000 loss: 0.0050 lr: 0.02\n",
      "iteration: 73000 loss: 0.0049 lr: 0.02\n",
      "iteration: 74000 loss: 0.0048 lr: 0.02\n",
      "iteration: 75000 loss: 0.0047 lr: 0.02\n",
      "iteration: 76000 loss: 0.0048 lr: 0.02\n",
      "iteration: 77000 loss: 0.0047 lr: 0.02\n",
      "iteration: 78000 loss: 0.0047 lr: 0.02\n",
      "iteration: 79000 loss: 0.0047 lr: 0.02\n",
      "iteration: 80000 loss: 0.0046 lr: 0.02\n",
      "iteration: 81000 loss: 0.0045 lr: 0.02\n",
      "iteration: 82000 loss: 0.0045 lr: 0.02\n",
      "iteration: 83000 loss: 0.0045 lr: 0.02\n",
      "iteration: 84000 loss: 0.0045 lr: 0.02\n",
      "iteration: 85000 loss: 0.0046 lr: 0.02\n",
      "iteration: 86000 loss: 0.0045 lr: 0.02\n",
      "iteration: 87000 loss: 0.0044 lr: 0.02\n",
      "iteration: 88000 loss: 0.0044 lr: 0.02\n",
      "iteration: 89000 loss: 0.0045 lr: 0.02\n",
      "iteration: 90000 loss: 0.0044 lr: 0.02\n",
      "iteration: 91000 loss: 0.0044 lr: 0.02\n",
      "iteration: 92000 loss: 0.0044 lr: 0.02\n",
      "iteration: 93000 loss: 0.0045 lr: 0.02\n",
      "iteration: 94000 loss: 0.0043 lr: 0.02\n",
      "iteration: 95000 loss: 0.0042 lr: 0.02\n",
      "iteration: 96000 loss: 0.0042 lr: 0.02\n",
      "iteration: 97000 loss: 0.0043 lr: 0.02\n",
      "iteration: 98000 loss: 0.0042 lr: 0.02\n",
      "iteration: 99000 loss: 0.0043 lr: 0.02\n",
      "iteration: 100000 loss: 0.0042 lr: 0.02\n",
      "iteration: 101000 loss: 0.0041 lr: 0.02\n",
      "iteration: 102000 loss: 0.0042 lr: 0.02\n",
      "iteration: 103000 loss: 0.0040 lr: 0.02\n",
      "iteration: 104000 loss: 0.0042 lr: 0.02\n",
      "iteration: 105000 loss: 0.0040 lr: 0.02\n",
      "iteration: 106000 loss: 0.0042 lr: 0.02\n",
      "iteration: 107000 loss: 0.0041 lr: 0.02\n",
      "iteration: 108000 loss: 0.0040 lr: 0.02\n",
      "iteration: 109000 loss: 0.0040 lr: 0.02\n",
      "iteration: 110000 loss: 0.0041 lr: 0.02\n",
      "iteration: 111000 loss: 0.0040 lr: 0.02\n",
      "iteration: 112000 loss: 0.0039 lr: 0.02\n",
      "iteration: 113000 loss: 0.0040 lr: 0.02\n",
      "iteration: 114000 loss: 0.0038 lr: 0.02\n",
      "iteration: 115000 loss: 0.0038 lr: 0.02\n",
      "iteration: 116000 loss: 0.0039 lr: 0.02\n",
      "iteration: 117000 loss: 0.0038 lr: 0.02\n",
      "iteration: 118000 loss: 0.0038 lr: 0.02\n",
      "iteration: 119000 loss: 0.0038 lr: 0.02\n",
      "iteration: 120000 loss: 0.0037 lr: 0.02\n",
      "iteration: 121000 loss: 0.0037 lr: 0.02\n",
      "iteration: 122000 loss: 0.0036 lr: 0.02\n",
      "iteration: 123000 loss: 0.0037 lr: 0.02\n",
      "iteration: 124000 loss: 0.0039 lr: 0.02\n",
      "iteration: 125000 loss: 0.0036 lr: 0.02\n",
      "iteration: 126000 loss: 0.0038 lr: 0.02\n",
      "iteration: 127000 loss: 0.0037 lr: 0.02\n",
      "iteration: 128000 loss: 0.0037 lr: 0.02\n",
      "iteration: 129000 loss: 0.0037 lr: 0.02\n",
      "iteration: 130000 loss: 0.0036 lr: 0.02\n",
      "iteration: 131000 loss: 0.0036 lr: 0.02\n",
      "iteration: 132000 loss: 0.0036 lr: 0.02\n",
      "iteration: 133000 loss: 0.0036 lr: 0.02\n",
      "iteration: 134000 loss: 0.0035 lr: 0.02\n",
      "iteration: 135000 loss: 0.0036 lr: 0.02\n",
      "iteration: 136000 loss: 0.0035 lr: 0.02\n",
      "iteration: 137000 loss: 0.0035 lr: 0.02\n",
      "iteration: 138000 loss: 0.0036 lr: 0.02\n",
      "iteration: 139000 loss: 0.0035 lr: 0.02\n",
      "iteration: 140000 loss: 0.0036 lr: 0.02\n",
      "iteration: 141000 loss: 0.0036 lr: 0.02\n",
      "iteration: 142000 loss: 0.0035 lr: 0.02\n",
      "iteration: 143000 loss: 0.0035 lr: 0.02\n",
      "iteration: 144000 loss: 0.0035 lr: 0.02\n",
      "iteration: 145000 loss: 0.0035 lr: 0.02\n",
      "iteration: 146000 loss: 0.0034 lr: 0.02\n",
      "iteration: 147000 loss: 0.0034 lr: 0.02\n",
      "iteration: 148000 loss: 0.0035 lr: 0.02\n",
      "iteration: 149000 loss: 0.0034 lr: 0.02\n",
      "iteration: 150000 loss: 0.0034 lr: 0.02\n",
      "iteration: 151000 loss: 0.0034 lr: 0.02\n",
      "iteration: 152000 loss: 0.0035 lr: 0.02\n",
      "iteration: 153000 loss: 0.0035 lr: 0.02\n",
      "iteration: 154000 loss: 0.0035 lr: 0.02\n",
      "iteration: 155000 loss: 0.0034 lr: 0.02\n",
      "iteration: 156000 loss: 0.0033 lr: 0.02\n",
      "iteration: 157000 loss: 0.0034 lr: 0.02\n",
      "iteration: 158000 loss: 0.0034 lr: 0.02\n",
      "iteration: 159000 loss: 0.0034 lr: 0.02\n",
      "iteration: 160000 loss: 0.0033 lr: 0.02\n",
      "iteration: 161000 loss: 0.0037 lr: 0.02\n",
      "iteration: 162000 loss: 0.0033 lr: 0.02\n",
      "iteration: 163000 loss: 0.0034 lr: 0.02\n",
      "iteration: 164000 loss: 0.0035 lr: 0.02\n",
      "iteration: 165000 loss: 0.0034 lr: 0.02\n",
      "iteration: 166000 loss: 0.0034 lr: 0.02\n",
      "iteration: 167000 loss: 0.0033 lr: 0.02\n",
      "iteration: 168000 loss: 0.0033 lr: 0.02\n",
      "iteration: 169000 loss: 0.0031 lr: 0.02\n",
      "iteration: 170000 loss: 0.0034 lr: 0.02\n",
      "iteration: 171000 loss: 0.0032 lr: 0.02\n",
      "iteration: 172000 loss: 0.0033 lr: 0.02\n",
      "iteration: 173000 loss: 0.0032 lr: 0.02\n",
      "iteration: 174000 loss: 0.0034 lr: 0.02\n",
      "iteration: 175000 loss: 0.0032 lr: 0.02\n",
      "iteration: 176000 loss: 0.0033 lr: 0.02\n",
      "iteration: 177000 loss: 0.0033 lr: 0.02\n",
      "iteration: 178000 loss: 0.0032 lr: 0.02\n",
      "iteration: 179000 loss: 0.0031 lr: 0.02\n",
      "iteration: 180000 loss: 0.0032 lr: 0.02\n",
      "iteration: 181000 loss: 0.0032 lr: 0.02\n",
      "iteration: 182000 loss: 0.0033 lr: 0.02\n",
      "iteration: 183000 loss: 0.0034 lr: 0.02\n",
      "iteration: 184000 loss: 0.0032 lr: 0.02\n",
      "iteration: 185000 loss: 0.0034 lr: 0.02\n",
      "iteration: 186000 loss: 0.0033 lr: 0.02\n",
      "iteration: 187000 loss: 0.0032 lr: 0.02\n",
      "iteration: 188000 loss: 0.0032 lr: 0.02\n",
      "iteration: 189000 loss: 0.0032 lr: 0.02\n",
      "iteration: 190000 loss: 0.0033 lr: 0.02\n",
      "iteration: 191000 loss: 0.0032 lr: 0.02\n",
      "iteration: 192000 loss: 0.0032 lr: 0.02\n",
      "iteration: 193000 loss: 0.0032 lr: 0.02\n",
      "iteration: 194000 loss: 0.0032 lr: 0.02\n",
      "iteration: 195000 loss: 0.0031 lr: 0.02\n",
      "iteration: 196000 loss: 0.0032 lr: 0.02\n",
      "iteration: 197000 loss: 0.0030 lr: 0.02\n",
      "iteration: 198000 loss: 0.0032 lr: 0.02\n",
      "iteration: 199000 loss: 0.0031 lr: 0.02\n",
      "iteration: 200000 loss: 0.0032 lr: 0.02\n",
      "iteration: 201000 loss: 0.0032 lr: 0.02\n",
      "iteration: 202000 loss: 0.0031 lr: 0.02\n",
      "iteration: 203000 loss: 0.0032 lr: 0.02\n",
      "iteration: 204000 loss: 0.0032 lr: 0.02\n",
      "iteration: 205000 loss: 0.0031 lr: 0.02\n",
      "iteration: 206000 loss: 0.0031 lr: 0.02\n",
      "iteration: 207000 loss: 0.0031 lr: 0.02\n",
      "iteration: 208000 loss: 0.0032 lr: 0.02\n",
      "iteration: 209000 loss: 0.0031 lr: 0.02\n",
      "iteration: 210000 loss: 0.0031 lr: 0.02\n",
      "iteration: 211000 loss: 0.0031 lr: 0.02\n",
      "iteration: 212000 loss: 0.0031 lr: 0.02\n",
      "iteration: 213000 loss: 0.0031 lr: 0.02\n",
      "iteration: 214000 loss: 0.0031 lr: 0.02\n",
      "iteration: 215000 loss: 0.0030 lr: 0.02\n",
      "iteration: 216000 loss: 0.0031 lr: 0.02\n",
      "iteration: 217000 loss: 0.0030 lr: 0.02\n",
      "iteration: 218000 loss: 0.0031 lr: 0.02\n",
      "iteration: 219000 loss: 0.0031 lr: 0.02\n",
      "iteration: 220000 loss: 0.0031 lr: 0.02\n",
      "iteration: 221000 loss: 0.0030 lr: 0.02\n",
      "iteration: 222000 loss: 0.0030 lr: 0.02\n",
      "iteration: 223000 loss: 0.0030 lr: 0.02\n",
      "iteration: 224000 loss: 0.0030 lr: 0.02\n",
      "iteration: 225000 loss: 0.0032 lr: 0.02\n",
      "iteration: 226000 loss: 0.0031 lr: 0.02\n",
      "iteration: 227000 loss: 0.0030 lr: 0.02\n",
      "iteration: 228000 loss: 0.0031 lr: 0.02\n",
      "iteration: 229000 loss: 0.0030 lr: 0.02\n",
      "iteration: 230000 loss: 0.0030 lr: 0.02\n",
      "iteration: 231000 loss: 0.0030 lr: 0.02\n",
      "iteration: 232000 loss: 0.0031 lr: 0.02\n",
      "iteration: 233000 loss: 0.0030 lr: 0.02\n",
      "iteration: 234000 loss: 0.0029 lr: 0.02\n",
      "iteration: 235000 loss: 0.0031 lr: 0.02\n",
      "iteration: 236000 loss: 0.0030 lr: 0.02\n",
      "iteration: 237000 loss: 0.0030 lr: 0.02\n",
      "iteration: 238000 loss: 0.0029 lr: 0.02\n",
      "iteration: 239000 loss: 0.0031 lr: 0.02\n",
      "iteration: 240000 loss: 0.0030 lr: 0.02\n",
      "iteration: 241000 loss: 0.0030 lr: 0.02\n",
      "iteration: 242000 loss: 0.0029 lr: 0.02\n",
      "iteration: 243000 loss: 0.0030 lr: 0.02\n",
      "iteration: 244000 loss: 0.0030 lr: 0.02\n",
      "iteration: 245000 loss: 0.0030 lr: 0.02\n",
      "iteration: 246000 loss: 0.0031 lr: 0.02\n",
      "iteration: 247000 loss: 0.0030 lr: 0.02\n",
      "iteration: 248000 loss: 0.0029 lr: 0.02\n",
      "iteration: 249000 loss: 0.0031 lr: 0.02\n",
      "iteration: 250000 loss: 0.0028 lr: 0.02\n",
      "iteration: 251000 loss: 0.0030 lr: 0.02\n",
      "iteration: 252000 loss: 0.0029 lr: 0.02\n",
      "iteration: 253000 loss: 0.0030 lr: 0.02\n",
      "iteration: 254000 loss: 0.0030 lr: 0.02\n",
      "iteration: 255000 loss: 0.0029 lr: 0.02\n",
      "iteration: 256000 loss: 0.0029 lr: 0.02\n",
      "iteration: 257000 loss: 0.0029 lr: 0.02\n",
      "iteration: 258000 loss: 0.0030 lr: 0.02\n",
      "iteration: 259000 loss: 0.0030 lr: 0.02\n",
      "iteration: 260000 loss: 0.0029 lr: 0.02\n",
      "iteration: 261000 loss: 0.0028 lr: 0.02\n",
      "iteration: 262000 loss: 0.0029 lr: 0.02\n",
      "iteration: 263000 loss: 0.0029 lr: 0.02\n",
      "iteration: 264000 loss: 0.0030 lr: 0.02\n",
      "iteration: 265000 loss: 0.0029 lr: 0.02\n",
      "iteration: 266000 loss: 0.0030 lr: 0.02\n",
      "iteration: 267000 loss: 0.0028 lr: 0.02\n",
      "iteration: 268000 loss: 0.0029 lr: 0.02\n",
      "iteration: 269000 loss: 0.0028 lr: 0.02\n",
      "iteration: 270000 loss: 0.0028 lr: 0.02\n",
      "iteration: 271000 loss: 0.0028 lr: 0.02\n",
      "iteration: 272000 loss: 0.0029 lr: 0.02\n",
      "iteration: 273000 loss: 0.0029 lr: 0.02\n",
      "iteration: 274000 loss: 0.0029 lr: 0.02\n",
      "iteration: 275000 loss: 0.0029 lr: 0.02\n",
      "iteration: 276000 loss: 0.0029 lr: 0.02\n",
      "iteration: 277000 loss: 0.0030 lr: 0.02\n",
      "iteration: 278000 loss: 0.0029 lr: 0.02\n",
      "iteration: 279000 loss: 0.0028 lr: 0.02\n",
      "iteration: 280000 loss: 0.0029 lr: 0.02\n",
      "iteration: 281000 loss: 0.0028 lr: 0.02\n",
      "iteration: 282000 loss: 0.0029 lr: 0.02\n",
      "iteration: 283000 loss: 0.0029 lr: 0.02\n",
      "iteration: 284000 loss: 0.0028 lr: 0.02\n",
      "iteration: 285000 loss: 0.0028 lr: 0.02\n",
      "iteration: 286000 loss: 0.0029 lr: 0.02\n",
      "iteration: 287000 loss: 0.0029 lr: 0.02\n",
      "iteration: 288000 loss: 0.0028 lr: 0.02\n",
      "iteration: 289000 loss: 0.0029 lr: 0.02\n",
      "iteration: 290000 loss: 0.0029 lr: 0.02\n",
      "iteration: 291000 loss: 0.0029 lr: 0.02\n",
      "iteration: 292000 loss: 0.0029 lr: 0.02\n",
      "iteration: 293000 loss: 0.0030 lr: 0.02\n",
      "iteration: 294000 loss: 0.0029 lr: 0.02\n",
      "iteration: 295000 loss: 0.0028 lr: 0.02\n",
      "iteration: 296000 loss: 0.0028 lr: 0.02\n",
      "iteration: 297000 loss: 0.0028 lr: 0.02\n",
      "iteration: 298000 loss: 0.0029 lr: 0.02\n",
      "iteration: 299000 loss: 0.0028 lr: 0.02\n",
      "iteration: 300000 loss: 0.0028 lr: 0.02\n",
      "iteration: 301000 loss: 0.0028 lr: 0.02\n",
      "iteration: 302000 loss: 0.0027 lr: 0.02\n",
      "iteration: 303000 loss: 0.0028 lr: 0.02\n",
      "iteration: 304000 loss: 0.0028 lr: 0.02\n",
      "iteration: 305000 loss: 0.0029 lr: 0.02\n",
      "iteration: 306000 loss: 0.0028 lr: 0.02\n",
      "iteration: 307000 loss: 0.0028 lr: 0.02\n",
      "iteration: 308000 loss: 0.0028 lr: 0.02\n",
      "iteration: 309000 loss: 0.0028 lr: 0.02\n",
      "iteration: 310000 loss: 0.0027 lr: 0.02\n",
      "iteration: 311000 loss: 0.0027 lr: 0.02\n",
      "iteration: 312000 loss: 0.0027 lr: 0.02\n",
      "iteration: 313000 loss: 0.0028 lr: 0.02\n",
      "iteration: 314000 loss: 0.0027 lr: 0.02\n",
      "iteration: 315000 loss: 0.0027 lr: 0.02\n",
      "iteration: 316000 loss: 0.0027 lr: 0.02\n",
      "iteration: 317000 loss: 0.0029 lr: 0.02\n",
      "iteration: 318000 loss: 0.0028 lr: 0.02\n",
      "iteration: 319000 loss: 0.0028 lr: 0.02\n",
      "iteration: 320000 loss: 0.0027 lr: 0.02\n",
      "iteration: 321000 loss: 0.0028 lr: 0.02\n",
      "iteration: 322000 loss: 0.0027 lr: 0.02\n",
      "iteration: 323000 loss: 0.0028 lr: 0.02\n",
      "iteration: 324000 loss: 0.0027 lr: 0.02\n",
      "iteration: 325000 loss: 0.0027 lr: 0.02\n",
      "iteration: 326000 loss: 0.0028 lr: 0.02\n",
      "iteration: 327000 loss: 0.0028 lr: 0.02\n",
      "iteration: 328000 loss: 0.0028 lr: 0.02\n",
      "iteration: 329000 loss: 0.0028 lr: 0.02\n",
      "iteration: 330000 loss: 0.0027 lr: 0.02\n",
      "iteration: 331000 loss: 0.0028 lr: 0.02\n",
      "iteration: 332000 loss: 0.0028 lr: 0.02\n",
      "iteration: 333000 loss: 0.0030 lr: 0.02\n",
      "iteration: 334000 loss: 0.0028 lr: 0.02\n",
      "iteration: 335000 loss: 0.0028 lr: 0.02\n",
      "iteration: 336000 loss: 0.0027 lr: 0.02\n",
      "iteration: 337000 loss: 0.0028 lr: 0.02\n",
      "iteration: 338000 loss: 0.0027 lr: 0.02\n",
      "iteration: 339000 loss: 0.0028 lr: 0.02\n",
      "iteration: 340000 loss: 0.0027 lr: 0.02\n",
      "iteration: 341000 loss: 0.0028 lr: 0.02\n",
      "iteration: 342000 loss: 0.0026 lr: 0.02\n",
      "iteration: 343000 loss: 0.0027 lr: 0.02\n"
     ]
    }
   ],
   "source": [
    "dlc.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'E:\\classical_fear_conditionning\\classical_fear_conditionning-BM-2020-11-20\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Y://classical_fear_conditionning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = ['Y://classical_fear_conditionning\\Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4',\n",
    "         'Y://classical_fear_conditionning\\Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4',\n",
    "         'Y://classical_fear_conditionning\\Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.filterpredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    \n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b029c3d71c03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'crop' is not defined"
     ]
    }
   ],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = ['Y://fear_conditionning_ptsd/Rat16/Rat16-20201202/Rat16_201202_171552/Basler_acA1300-200uc__23039139__20201202_171555498.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in videos:\n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.launch_dlc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DLC-GPU] *",
   "language": "python",
   "name": "conda-env-.conda-DLC-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
