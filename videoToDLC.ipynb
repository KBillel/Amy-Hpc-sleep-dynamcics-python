{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib qt\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global x,y,pause\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.imshow(frame)\n",
    "    try:\n",
    "        x\n",
    "    except:\n",
    "        x = [0,0]\n",
    "    try:\n",
    "        y\n",
    "    except:\n",
    "        y = [0,0]\n",
    "    \n",
    "    if str(event.button) == \"MouseButton.LEFT\":\n",
    "        x[0], y[0] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.RIGHT\":\n",
    "        x[1], y[1] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.MIDDLE\":\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "        pause = False\n",
    "        \n",
    "    for i,j in zip(x,y):\n",
    "        plt.axvline(i)\n",
    "        plt.axhline(j)\n",
    "        plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Y:/elevated_plus_maze/'\n",
    "videos = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4') and not file.endswith('labeled.mp4'): videos.append(os.path.join(subdirs,file))\n",
    "\n",
    "            \n",
    "config_path = 'Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y:/elevated_plus_maze/Rat06-20201123\\\\Rat06_201123_152703\\\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat07-20201123\\\\Rat07_201123_154150\\\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat08-20201123\\\\Rat08_201123_155820\\\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat09-20201130\\\\Rat09_201130_145247\\\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat10-20201130\\\\Rat10_201130_150837\\\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat11-20201130\\\\Rat11_201130_152319\\\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4',\n",
       " 'Y:/elevated_plus_maze/Rat12-20201130\\\\Rat12_201130_153751\\\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = []\n",
    "\n",
    "for v in videos:\n",
    "    try:\n",
    "        del x,y\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cap = cv2.VideoCapture(v)\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    pause = True\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.imshow(frame)\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "    \n",
    "    while pause:\n",
    "        plt.pause(0.1)\n",
    "        \n",
    "    plt.close('all')\n",
    "    crop.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([293.1796536796537, 1199.15367965368],\n",
       "  [42.166666666666515, 632.2965367965367]),\n",
       " ([301.491341991342, 1190.8419913419916],\n",
       "  [36.62554112554085, 643.3787878787878]),\n",
       " ([271.0151515151515, 1188.071428571429],\n",
       "  [42.166666666666515, 635.0670995670995]),\n",
       " ([287.63852813852816, 1190.8419913419916],\n",
       "  [72.64285714285688, 665.54329004329]),\n",
       " ([307.03246753246754, 1193.6125541125546],\n",
       "  [61.56060606060578, 673.8549783549782]),\n",
       " ([301.491341991342, 1179.7597402597407],\n",
       "  [44.937229437229234, 623.9848484848484]),\n",
       " ([282.0974025974026, 1176.9891774891778],\n",
       "  [28.31385281385269, 607.3614718614717])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [293, 1199, 42, 632]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-650000 for model Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\dlc-models\\iteration-3\\elevated_plus_mazeDec01-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/17534 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat06-20201123\\Rat06_201123_152703\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4\n",
      "Y:\\elevated_plus_maze\\Rat06-20201123\\Rat06_201123_152703  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat06-20201123\\Rat06_201123_152703\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4\n",
      "Duration of video [s]:  584.47 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17534  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 293 x2 = 1199 y1 = 42 y2 = 632. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17675it [09:51, 29.69it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17675it [09:52, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat06-20201123\\Rat06_201123_152703...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat06-20201123\\Rat06_201123_152703\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [301, 1190, 36, 643]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-650000 for model Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\dlc-models\\iteration-3\\elevated_plus_mazeDec01-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/17662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat07-20201123\\Rat07_201123_154150\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4\n",
      "Y:\\elevated_plus_maze\\Rat07-20201123\\Rat07_201123_154150  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat07-20201123\\Rat07_201123_154150\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4\n",
      "Duration of video [s]:  588.73 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17662  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 301 x2 = 1190 y1 = 36 y2 = 643. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17776it [09:45, 30.36it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17662\n",
      "Saving results in Y:\\elevated_plus_maze\\Rat07-20201123\\Rat07_201123_154150...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat07-20201123\\Rat07_201123_154150\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [271, 1188, 42, 635]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-650000 for model Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\dlc-models\\iteration-3\\elevated_plus_mazeDec01-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/17839 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat08-20201123\\Rat08_201123_155820\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4\n",
      "Y:\\elevated_plus_maze\\Rat08-20201123\\Rat08_201123_155820  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat08-20201123\\Rat08_201123_155820\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4\n",
      "Duration of video [s]:  594.63 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17839  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 271 x2 = 1188 y1 = 42 y2 = 635. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17978it [10:11, 29.13it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17978it [10:12, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat08-20201123\\Rat08_201123_155820...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat08-20201123\\Rat08_201123_155820\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [287, 1190, 72, 665]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-650000 for model Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\dlc-models\\iteration-3\\elevated_plus_mazeDec01-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/17539 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat09-20201130\\Rat09_201130_145247\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4\n",
      "Y:\\elevated_plus_maze\\Rat09-20201130\\Rat09_201130_145247  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat09-20201130\\Rat09_201130_145247\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4\n",
      "Duration of video [s]:  584.63 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17539  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 287 x2 = 1190 y1 = 72 y2 = 665. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17675it [09:47, 30.07it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Y:\\elevated_plus_maze\\Rat09-20201130\\Rat09_201130_145247...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat09-20201130\\Rat09_201130_145247\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [307, 1193, 61, 673]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-650000 for model Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\dlc-models\\iteration-3\\elevated_plus_mazeDec01-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/17755 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat10-20201130\\Rat10_201130_150837\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4\n",
      "Y:\\elevated_plus_maze\\Rat10-20201130\\Rat10_201130_150837  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat10-20201130\\Rat10_201130_150837\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4\n",
      "Duration of video [s]:  591.83 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17755  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 307 x2 = 1193 y1 = 61 y2 = 673. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17877it [10:02, 29.69it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17755\n",
      "Saving results in Y:\\elevated_plus_maze\\Rat10-20201130\\Rat10_201130_150837...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat10-20201130\\Rat10_201130_150837\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [301, 1179, 44, 623]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-650000 for model Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\dlc-models\\iteration-3\\elevated_plus_mazeDec01-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/17943 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat11-20201130\\Rat11_201130_152319\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4\n",
      "Y:\\elevated_plus_maze\\Rat11-20201130\\Rat11_201130_152319  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat11-20201130\\Rat11_201130_152319\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4\n",
      "Duration of video [s]:  598.1 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17943  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 301 x2 = 1179 y1 = 44 y2 = 623. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18079it [09:42, 31.03it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17943\n",
      "Saving results in Y:\\elevated_plus_maze\\Rat11-20201130\\Rat11_201130_152319...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat11-20201130\\Rat11_201130_152319\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [282, 1176, 28, 607]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-650000 for model Y:\\elevated_plus_maze\\elevated_plus_maze-BM-2020-12-01\\dlc-models\\iteration-3\\elevated_plus_mazeDec01-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/17936 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Y:/elevated_plus_maze/Rat12-20201130\\Rat12_201130_153751\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4\n",
      "Y:\\elevated_plus_maze\\Rat12-20201130\\Rat12_201130_153751  already exists!\n",
      "Loading  Y:/elevated_plus_maze/Rat12-20201130\\Rat12_201130_153751\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4\n",
      "Duration of video [s]:  597.87 , recorded with  30.0 fps!\n",
      "Overall # of frames:  17936  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 282 x2 = 1176 y1 = 28 y2 = 607. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18079it [09:43, 30.98it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  17936\n",
      "Saving results in Y:\\elevated_plus_maze\\Rat12-20201130\\Rat12_201130_153751...\n",
      "Saving csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with arima model Y:/elevated_plus_maze/Rat12-20201130\\Rat12_201130_153751\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\maelle.christiaens\\.conda\\envs\\DLC-GPU\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.analyze_videos(config_path,v,cropping=c,save_as_csv=True)\n",
    "    dlc.filterpredictions(config_path,v,save_as_csv = True,filtertype='arima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pickle'): metadata.append(os.path.join(subdirs,file))\n",
    "\n",
    "del metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in videos:\n",
    "    dlc.create_labeled_video(config_path,v,filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  458  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20201123_152706224  already extracted (more will be added)!\n",
      "Loading video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 23.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of video [s]:  584.467 , recorded @  30.0 fps!\n",
      "Overall # of frames:  17534 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 584.47  seconds.\n",
      "Extracting and downsampling... 458  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "458it [00:14, 32.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [13417, 177, 36, 107, 129, 162, 149, 91, 151, 185]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y:/elevated_plus_maze/Rat06-20201123\\Rat06_201123_152703\\Basler_acA1300-200uc__23039139__20201123_152706224.mp4 Coordinates for cropping: (293, 1199, 42, 632)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201123_152706224.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  534  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20201123_154152804  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  588.734 , recorded @  30.0 fps!\n",
      "Overall # of frames:  17662 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 588.73  seconds.\n",
      "Extracting and downsampling... 534  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "534it [00:15, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [225, 1380, 54, 215, 183, 244, 222, 156, 206, 213]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y:/elevated_plus_maze/Rat07-20201123\\Rat07_201123_154150\\Basler_acA1300-200uc__23039139__20201123_154152804.mp4 Coordinates for cropping: (301, 1190, 36, 643)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201123_154152804.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1324  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20201123_155821934  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  594.634 , recorded @  30.0 fps!\n",
      "Overall # of frames:  17839 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 594.63  seconds.\n",
      "Extracting and downsampling... 1324  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1324it [00:38, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2110, 271, 433, 415, 382, 341, 448, 14, 352, 486]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y:/elevated_plus_maze/Rat08-20201123\\Rat08_201123_155820\\Basler_acA1300-200uc__23039139__20201123_155821934.mp4 Coordinates for cropping: (271, 1188, 42, 635)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201123_155821934.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  699  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20201130_145248866  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  584.634 , recorded @  30.0 fps!\n",
      "Overall # of frames:  17539 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 584.63  seconds.\n",
      "Extracting and downsampling... 699  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [00:22, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [6584, 101, 146, 126, 112, 176, 165, 13378, 124, 108]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y:/elevated_plus_maze/Rat09-20201130\\Rat09_201130_145247\\Basler_acA1300-200uc__23039139__20201130_145248866.mp4 Coordinates for cropping: (287, 1190, 72, 665)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201130_145248866.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  547  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20201130_150839776  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  591.834 , recorded @  30.0 fps!\n",
      "Overall # of frames:  17755 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 591.83  seconds.\n",
      "Extracting and downsampling... 547  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "547it [00:17, 31.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [14457, 444, 349, 237, 291, 377, 3839, 306, 455, 393]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y:/elevated_plus_maze/Rat10-20201130\\Rat10_201130_150837\\Basler_acA1300-200uc__23039139__20201130_150839776.mp4 Coordinates for cropping: (307, 1193, 61, 673)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201130_150839776.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  783  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20201130_152321432  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  598.1 , recorded @  30.0 fps!\n",
      "Overall # of frames:  17943 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 598.1  seconds.\n",
      "Extracting and downsampling... 783  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "783it [00:23, 32.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [229, 13654, 594, 540, 608, 522, 572, 551, 531, 519]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y:/elevated_plus_maze/Rat11-20201130\\Rat11_201130_152319\\Basler_acA1300-200uc__23039139__20201130_152321432.mp4 Coordinates for cropping: (301, 1179, 44, 623)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201130_152321432.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  527  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20201130_153753849  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  597.867 , recorded @  30.0 fps!\n",
      "Overall # of frames:  17936 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 597.87  seconds.\n",
      "Extracting and downsampling... 527  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "527it [00:13, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [586, 341, 7693, 77, 481, 599, 536, 171, 247, 570]\n",
      "Creating the symbolic link of the video\n",
      "AUTOMATIC ADDING OF VIDEO TO CONFIG FILE FAILED! You need to do this manually for including it in the config.yaml file!\n",
      "Videopath: Y:/elevated_plus_maze/Rat12-20201130\\Rat12_201130_153751\\Basler_acA1300-200uc__23039139__20201130_153753849.mp4 Coordinates for cropping: (282, 1176, 28, 607)\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20201130_153753849.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    \n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    \n",
    "    dlc.extract_outlier_frames(config_path,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 4.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 78,  23,  57,  63, 106,   4, 102,  85,  66,   8,  21,  52, 119,\n",
       "           37, 123, 122, 109, 126, 100,  69,  26,  70,  84,  65,  18, 124,\n",
       "           83,  30,  40,  14,  47,   5, 104, 128,  33,  34,  44,  76,  25,\n",
       "            2,  38,   1,  68,  77,   6,  93,  96,  92,  32, 113,  43, 101,\n",
       "           42,  59,  31, 116, 114,  15,  67,  94,   3,  22,  58,  75,  48,\n",
       "           27,  13,  88,  41,  28,   0,   7, 107,  81, 117,  71, 121,  20,\n",
       "           53, 103,   9,  10,  61,  54,  45,  46,  50, 105,  89,  36,  97,\n",
       "           95,  24,  72,  51,  91,  90,  11,  35,  12,  19, 120, 115, 112,\n",
       "           64,  17,  87,  39,  74,  60,  86, 129,  29,  16, 118, 111,  80,\n",
       "           56, 127,  98, 110,  79, 125]),\n",
       "   array([ 49, 108,  99,  62,  82,  55,  73])))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['snout', 'left_ear', 'right_ear', 'b_tail', 'e_tail'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\elevated_plus_maze_Maelle95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\maelle.christiaens\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\Documentation_data-elevated_plus_maze_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01\\\\dlc-models\\\\iteration-4\\\\elevated_plus_mazeDec01-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01\\\\dlc-models\\\\iteration-4\\\\elevated_plus_mazeDec01-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4]], 'all_joints_names': ['snout', 'left_ear', 'right_ear', 'b_tail', 'e_tail'], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\elevated_plus_maze_Maelle95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\maelle.christiaens\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-4\\\\UnaugmentedDataSet_elevated_plus_mazeDec01\\\\Documentation_data-elevated_plus_maze_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 5, 'pos_dist_thresh': 17, 'project_path': 'Y:\\\\elevated_plus_maze\\\\elevated_plus_maze-BM-2020-12-01', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0289 lr: 0.005\n",
      "iteration: 2000 loss: 0.0215 lr: 0.005\n",
      "iteration: 3000 loss: 0.0180 lr: 0.005\n",
      "iteration: 4000 loss: 0.0150 lr: 0.005\n",
      "iteration: 5000 loss: 0.0136 lr: 0.005\n",
      "iteration: 6000 loss: 0.0122 lr: 0.005\n",
      "iteration: 7000 loss: 0.0112 lr: 0.005\n",
      "iteration: 8000 loss: 0.0107 lr: 0.005\n",
      "iteration: 9000 loss: 0.0092 lr: 0.005\n",
      "iteration: 10000 loss: 0.0089 lr: 0.005\n",
      "iteration: 11000 loss: 0.0128 lr: 0.02\n",
      "iteration: 12000 loss: 0.0103 lr: 0.02\n",
      "iteration: 13000 loss: 0.0089 lr: 0.02\n",
      "iteration: 14000 loss: 0.0076 lr: 0.02\n",
      "iteration: 15000 loss: 0.0069 lr: 0.02\n"
     ]
    }
   ],
   "source": [
    "dlc.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.launch_dlc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
