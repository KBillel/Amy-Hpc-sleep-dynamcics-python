{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    global x,y,pause\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.imshow(frame)\n",
    "    try:\n",
    "        x\n",
    "    except:\n",
    "        x = [0,0]\n",
    "    try:\n",
    "        y\n",
    "    except:\n",
    "        y = [0,0]\n",
    "    \n",
    "    if str(event.button) == \"MouseButton.LEFT\":\n",
    "        x[0], y[0] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.RIGHT\":\n",
    "        x[1], y[1] = event.xdata, event.ydata\n",
    "    elif str(event.button) == \"MouseButton.MIDDLE\":\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "        pause = False\n",
    "        \n",
    "    for i,j in zip(x,y):\n",
    "        plt.axvline(i)\n",
    "        plt.axhline(j)\n",
    "        plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/DeepLabCut_Tutorial_Temps/MonExperience/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_152809\\\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_103618\\\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_143126\\\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24-20210129_210129_163341\\\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_113321\\\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_152259\\\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4') and not file.endswith('labeled.mp4'): videos.append(os.path.join(subdirs,file))\n",
    "# config_path = 'E:\\classical_fear_conditionning\\classical_fear_conditionning-BM-2020-11-20\\config.yaml'\n",
    "videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter\n",
      "outer\n",
      "close\n",
      "enter\n",
      "outer\n",
      "close\n",
      "enter\n",
      "outer\n",
      "close\n",
      "enter\n",
      "outer\n",
      "close\n",
      "enter\n",
      "outer\n",
      "close\n",
      "enter\n",
      "outer\n",
      "close\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([525.4316415801771, 870.4188719230561],\n",
       "  [187.68496984187345, 510.4149595174699]),\n",
       " ([475.35285007879156, 990.0515405096997],\n",
       "  [234.98160625984883, 521.5435798511111]),\n",
       " ([464.2242297451503, 1012.308781176982],\n",
       "  [201.59574525892504, 493.722029017008]),\n",
       " ([519.8673314133565, 862.0724066728252],\n",
       "  [165.42772917459092, 468.6826332663152]),\n",
       " ([475.35285007879156, 981.7050752594688],\n",
       "  [209.94221050915598, 515.9792696842906]),\n",
       " ([478.1350051622019, 987.2693854262894],\n",
       "  [218.28867575938693, 507.6328044340596])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop = []\n",
    "for v in videos:\n",
    "    try:\n",
    "        del x,y\n",
    "    except:\n",
    "        pass\n",
    "    cap = cv2.VideoCapture(v)\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    pause = True\n",
    "    fig,ax = plt.subplots()\n",
    "    plt.imshow(frame)\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "    while pause:\n",
    "        plt.pause(0.1)\n",
    "    plt.close('all')\n",
    "    crop.append((x,y))\n",
    "    \n",
    "crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Videos : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cropping parameters: [525, 870, 187, 510]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19667 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_152809\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_152809  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_152809\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4\n",
      "Duration of video [s]:  655.57 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19667  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 525 x2 = 870 y1 = 187 y2 = 510. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19796it [05:20, 61.70it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_152809...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_152809\\Basler_acA1300-200uc__23039139__20210128_152809881.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [475, 990, 234, 521]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19098 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_103618\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_103618  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_103618\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4\n",
      "Duration of video [s]:  636.6 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19098  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 475 x2 = 990 y1 = 234 y2 = 521. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19190it [05:34, 57.35it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_103618...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_103618\\Basler_acA1300-200uc__23039139__20210128_103619873.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [464, 1012, 201, 493]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19779 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_143126\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_143126  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_143126\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4\n",
      "Duration of video [s]:  659.3 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19779  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 464 x2 = 1012 y1 = 201 y2 = 493. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19897it [05:46, 57.45it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat23\\Rat23-20210128_210128_143126...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\Rat23-20210128_210128_143126\\Basler_acA1300-200uc__23039139__20210128_143130383.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [519, 862, 165, 468]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19336 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24-20210129_210129_163341  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4\n",
      "Duration of video [s]:  644.53 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19336  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 519 x2 = 862 y1 = 165 y2 = 468. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19493it [04:56, 65.84it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24-20210129_210129_163341...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [475, 981, 209, 515]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19202 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_113321  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4\n",
      "Duration of video [s]:  640.07 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19202  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 475 x2 = 981 y1 = 209 y2 = 515. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19392it [05:36, 57.71it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_113321...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4\n",
      "Saving filtered csv poses!\n",
      "Overwriting cropping parameters: [478, 987, 218, 507]\n",
      "These are used for all videos, but won't be save to the cfg file.\n",
      "Using snapshot-4000 for model D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\dlc-models\\iteration-0\\fear_tuto_dlcFeb15-trainset95shuffle1\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/19159 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4\n",
      "D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_152259  already exists!\n",
      "Loading  D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4\n",
      "Duration of video [s]:  638.63 , recorded with  30.0 fps!\n",
      "Overall # of frames:  19159  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n",
      "Cropping based on the x1 = 478 x2 = 987 y1 = 218 y2 = 507. You can adjust the cropping coordinates in the config.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19291it [05:29, 58.49it/s]                                                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in D:\\DeepLabCut_Tutorial_Temps\\MonExperience\\Rat24\\Rat24_20210129_210129_152259...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Filtering with median model D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.analyze_videos(config_path,v,cropping=c,save_as_csv=True)\n",
    "    dlc.filterpredictions(config_path,v,save_as_csv = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create labeled Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select if you want to user filtered positions or not\n",
    "filt = False\n",
    "for v in videos:\n",
    "    dlc.create_labeled_video(config_path,v,filtered=filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Crop metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_152809\\\\Basler_acA1300-200uc__23039139__20210128_152809881DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_103618\\\\Basler_acA1300-200uc__23039139__20210128_103619873DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat23\\\\Rat23-20210128_210128_143126\\\\Basler_acA1300-200uc__23039139__20210128_143130383DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24-20210129_210129_163341\\\\Basler_acA1300-200uc__23039139__20210129_163346459DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_113321\\\\Basler_acA1300-200uc__23039139__20210129_113328761DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle',\n",
       " 'D:/DeepLabCut_Tutorial_Temps/MonExperience/Rat24\\\\Rat24_20210129_210129_152259\\\\Basler_acA1300-200uc__23039139__20210129_152304254DLC_resnet_50_fear_tuto_dlcFeb15shuffle1_4000_meta.pickle']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = []\n",
    "for subdirs, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pickle'): metadata.append(os.path.join(subdirs,file))\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract outliers frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525 870 187 510\n",
      "Method  jump  found  3216  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video Basler_acA1300-200uc__23039139__20210128_152809881  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  655.5666666666667 , recorded @  30.0 fps!\n",
      "Overall # of frames:  19667 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 655.57  seconds.\n",
      "Extracting and downsampling... 3216  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3216it [01:10, 45.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [4823, 178, 19584, 645, 14415, 4157, 249, 1182, 669, 19655, 663, 594, 1593, 10447, 474, 10949, 19540, 8604, 19572, 13861]\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Basler_acA1300-200uc__23039139__20210128_152809881.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "475 990 234 521\n",
      "Method  jump  found  2498  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "464 1012 201 493\n",
      "Method  jump  found  1005  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "519 862 165 468\n",
      "Method  jump  found  3275  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "475 981 209 515\n",
      "Method  jump  found  2903  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n",
      "478 987 218 507\n",
      "Method  jump  found  3260  putative outlier frames.\n",
      "Do you want to proceed with extracting  20  of those?\n",
      "If this list is very large, perhaps consider changing the parameters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extracted, please change the parameters and start again...\n"
     ]
    }
   ],
   "source": [
    "numframes2pick = 20\n",
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    print(x1,x2,y1,y2)\n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    \n",
    "    cfg['numframes2pick'] = numframes2pick\n",
    "    cfg['cropping'] = True    \n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    \n",
    "    dlc.extract_outlier_frames(config_path,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                           | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Billel.\n",
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210128_152809881_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:04<00:00, 10.23it/s]\n",
      "  0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210128_103619873_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 11.48it/s]\n",
      "  0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210128_143130383_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 11.28it/s]\n",
      "  0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210129_113328761_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 11.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.94it/s]\n",
      "  0%|                                                                                                                                           | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15\\labeled-data\\Basler_acA1300-200uc__23039139__20210128_152809881_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:04<00:00, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 1.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([33, 89, 52,  3, 90, 17, 43, 67, 59, 94, 44, 65, 25, 18, 37, 64, 74,\n",
       "           5, 75, 30, 38, 97, 19, 26,  7, 83, 70, 35, 85, 82,  8, 73, 78, 23,\n",
       "          36, 32, 92,  9, 87, 58, 88, 40, 31, 98, 55, 54, 91, 22,  2, 68, 61,\n",
       "          15, 48,  6, 57, 80, 50, 21, 27, 56, 77, 16, 46,  4, 42, 96, 28, 63,\n",
       "          71, 12, 34, 66, 53, 47, 72, 41, 81, 39, 95, 45, 13, 69, 24, 51, 60,\n",
       "          11, 93, 14, 10, 76, 79, 84, 29, 49]),\n",
       "   array([20,  1, 86,  0, 62])))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['snout',\n",
      "                      'left_ear',\n",
      "                      'right_ear',\n",
      "                      'base_tail',\n",
      "                      'end_tail'],\n",
      " 'alpha_r': 0.02,\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\fear_tuto_dlc_Billel95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Billel.Khouader\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\Documentation_data-fear_tuto_dlc_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'D:\\\\DeepLabCut_Tutorial_Temps\\\\fear_tuto_dlc-Billel-2021-02-15\\\\dlc-models\\\\iteration-1\\\\fear_tuto_dlcFeb15-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'D:\\\\DeepLabCut_Tutorial_Temps\\\\fear_tuto_dlc-Billel-2021-02-15\\\\dlc-models\\\\iteration-1\\\\fear_tuto_dlcFeb15-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4]], 'all_joints_names': ['snout', 'left_ear', 'right_ear', 'base_tail', 'end_tail'], 'alpha_r': 0.02, 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\fear_tuto_dlc_Billel95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\Billel.Khouader\\\\.conda\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_fear_tuto_dlcFeb15\\\\Documentation_data-fear_tuto_dlc_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 5, 'pos_dist_thresh': 17, 'project_path': 'D:/DeepLabCut_Tutorial_Temps/fear_tuto_dlc-Billel-2021-02-15', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0448 lr: 0.005\n",
      "iteration: 2000 loss: 0.0292 lr: 0.005\n",
      "iteration: 3000 loss: 0.0228 lr: 0.005\n",
      "iteration: 4000 loss: 0.0191 lr: 0.005\n",
      "iteration: 5000 loss: 0.0169 lr: 0.005\n",
      "iteration: 6000 loss: 0.0147 lr: 0.005\n",
      "iteration: 7000 loss: 0.0133 lr: 0.005\n",
      "iteration: 8000 loss: 0.0125 lr: 0.005\n",
      "iteration: 9000 loss: 0.0118 lr: 0.005\n",
      "iteration: 10000 loss: 0.0112 lr: 0.005\n",
      "iteration: 11000 loss: 0.0160 lr: 0.02\n",
      "iteration: 12000 loss: 0.0131 lr: 0.02\n",
      "iteration: 13000 loss: 0.0119 lr: 0.02\n",
      "iteration: 14000 loss: 0.0108 lr: 0.02\n",
      "iteration: 15000 loss: 0.0103 lr: 0.02\n",
      "iteration: 16000 loss: 0.0096 lr: 0.02\n",
      "iteration: 17000 loss: 0.0094 lr: 0.02\n",
      "iteration: 18000 loss: 0.0089 lr: 0.02\n",
      "iteration: 19000 loss: 0.0086 lr: 0.02\n",
      "iteration: 20000 loss: 0.0084 lr: 0.02\n",
      "iteration: 21000 loss: 0.0081 lr: 0.02\n",
      "iteration: 22000 loss: 0.0079 lr: 0.02\n",
      "iteration: 23000 loss: 0.0077 lr: 0.02\n",
      "iteration: 24000 loss: 0.0076 lr: 0.02\n",
      "iteration: 25000 loss: 0.0075 lr: 0.02\n",
      "iteration: 26000 loss: 0.0074 lr: 0.02\n",
      "iteration: 27000 loss: 0.0074 lr: 0.02\n",
      "iteration: 28000 loss: 0.0072 lr: 0.02\n",
      "iteration: 29000 loss: 0.0069 lr: 0.02\n",
      "iteration: 30000 loss: 0.0071 lr: 0.02\n",
      "iteration: 31000 loss: 0.0067 lr: 0.02\n",
      "iteration: 32000 loss: 0.0067 lr: 0.02\n"
     ]
    }
   ],
   "source": [
    "dlc.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'E:\\classical_fear_conditionning\\classical_fear_conditionning-BM-2020-11-20\\config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Y://classical_fear_conditionning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = ['Y://classical_fear_conditionning\\Rat24\\Rat24_20210129_210129_113321\\Basler_acA1300-200uc__23039139__20210129_113328761.mp4',\n",
    "         'Y://classical_fear_conditionning\\Rat24\\Rat24_20210129_210129_152259\\Basler_acA1300-200uc__23039139__20210129_152304254.mp4',\n",
    "         'Y://classical_fear_conditionning\\Rat24\\Rat24-20210129_210129_163341\\Basler_acA1300-200uc__23039139__20210129_163346459.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.filterpredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v,m in zip(videos,metadata):\n",
    "    with open(m,'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    x1,x2,y1,y2 = data['data']['cropping_parameters']\n",
    "    \n",
    "    cfg = dlc.utils.auxiliaryfunctions.read_config(config_path)\n",
    "    cfg['x1'] = x1\n",
    "    cfg['x2'] = x2\n",
    "    cfg['y1'] = y1\n",
    "    cfg['y2'] = y2\n",
    "    dlc.utils.auxiliaryfunctions.write_config(config_path,cfg)\n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b029c3d71c03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'crop' is not defined"
     ]
    }
   ],
   "source": [
    "for v,c in zip(videos,crop):\n",
    "    x1,x2 = c[0]\n",
    "    y1,y2 = c[1]\n",
    "    c = [x1,x2,y1,y2]\n",
    "    c = list(map(int,c))\n",
    "    \n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = ['Y://fear_conditionning_ptsd/Rat16/Rat16-20201202/Rat16_201202_171552/Basler_acA1300-200uc__23039139__20201202_171555498.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in videos:\n",
    "    dlc.create_labeled_video(config_path,v,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.evaluate_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.launch_dlc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DLC-GPU] *",
   "language": "python",
   "name": "conda-env-.conda-DLC-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
